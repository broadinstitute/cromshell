#!/usr/bin/env bash

################################################################################

# Setup variables for the script:
UNALIASED_SCRIPT_NAME=$( python -c "import os;print (os.path.realpath(\"${BASH_SOURCE[0]}\"))" )
SCRIPTDIR="$( cd "$( dirname "${UNALIASED_SCRIPT_NAME}" )" && pwd )"
SCRIPTNAME=$( echo $0 | sed 's#.*/##g' )
MINARGS=1
MAXARGS=99
PREREQUISITES="curl jq mail column"

# Determine if this shell is interactive:
ISCALLEDBYUSER=true
[[ "${BASH_SOURCE[0]}" != "${0}" ]] && ISCALLEDBYUSER=false

# Required for the aliased call to checkPipeStatus:
shopt -s expand_aliases

################################################################################
COLOR_NORM='\033[0m'
COLOR_UNDERLINED='\033[1;4m'
COLOR_FAILED='\033[1;37;41m'
COLOR_SUCCEEDED='\033[1;30;42m'
COLOR_RUNNING='\033[0;30;46m'
################################################################################

COLOR_FAILED='\033[1;37;41m'
COLOR_SUCCEEDED='\033[1;30;42m'
COLOR_RUNNING='\033[0;30;46m'
################################################################################

# read env var, or use default server URL
export CROMWELL_URL=${CROMWELL_URL:-"https://cromwell-v36.dsde-methods.broadinstitute.org"}

FOLDER_URL=$( echo ${CROMWELL_URL} | sed -e 's#ht.*://##g' ) 

CROMSHELL_CONFIG_DIR=${HOME}/.cromshell
mkdir -p ${CROMSHELL_CONFIG_DIR}

CROMWELL_METADATA_PARAMETERS="excludeKey=submittedFiles&expandSubWorkflows=true"
CROMWELL_SUBMISSIONS_FILE="${CROMSHELL_CONFIG_DIR}/all.workflow.database.tsv"

[ ! -f ${CROMWELL_SUBMISSIONS_FILE} ] && echo -e "DATE\tCROMWELL_SERVER\tRUN_ID\tWDL_NAME\tSTATUS" > ${CROMWELL_SUBMISSIONS_FILE} 

CURL_CONNECT_TIMEOUT=5

PING_CMD='ping -c1 -W1 -w10'
if [[ $( uname ) == "Darwin" ]] ; then
  PING_CMD='ping -c1 -W1000 -t10'
fi

################################################################################

SUB_COMMAND=''
WORKFLOW_ID=''
WORKFLOW_SERVER_URL=''
OPTIONS=''

################################################################################

function turtle() 
{
  if [[ -z $1 ]]; then
    eye="'"
  else
    eye=x
  fi
  error "                  __     "
  error "       .,-;-;-,. /${eye}_\\    "
  error "     _/_/_/_|_\\_\\) /     "
  error "   '-<_><_><_><_>=/\\     "
  error "     \`/_/====/_/-'\\_\\    " 
  error "      \"\"     \"\"    \"\"    " 
}

function turtleDead()
{
  error "    ,,    ,,     ,,       "
  error "    \\‾\\,-/‾/====/‾/,     "
  error "     \\/=<‾><‾><‾><‾>-,   "
  error "     / (\\‾\\‾|‾/‾/‾/‾     "
  error "    \\‾x/ ˙'-;-;-'˙       "
  error "     ‾‾                  "
}

function thoughtBubble() 
{

  echo "          .-~~~-.              " 
  echo "  .- ~ ~-(       )_ _          "  
  echo " /                     ~ -.    "    
  echo "|         CROMSHELL       \\  "      
  echo " \\                         .'  "      
  echo "   ~- . _           _ . -~     "   
  echo "         ~~~~~~~~~~~"        
  echo "               () "
  echo "                o "
  echo "                 ."
}

function logo()
{
	echo
	echo '  +--------------------------+'
	echo '  |        CROMSHELL         |'
	echo '  +--------------------------+'
  turtle
	echo
}

################################################################################

function simpleUsage()
{
  echo -e "Usage:    ${SCRIPTNAME} <subcommand> [options]"
  echo -e "Run and inspect workflows on a Cromwell server."
}

#Define a usage function:
function usage() 
{
  simpleUsage
  echo -e
  echo -e "CROMWELL_URL=$CROMWELL_URL"
  echo
  echo -e "If no workflow-id is specified then the last submitted workflow-id is assumed."
  echo -e "Alternatively, negative numbers can be used to refer to previous workflows."
  echo
  echo -e "  example usage:"
  echo -e "      cromshell submit workflow.wdl inputs.json options.json dependencies.zip"
  echo -e "      cromshell status"
  echo -e "      cromshell logs -2"
  echo
  echo -e "Supported Subcommands:"
  echo -e "  Start/Stop workflows"
  echo -e "   submit <wdl> <inputs json> [options json] [included wdls] Submit a new workflow"
  echo -e "   abort [workflow-id] [[workflow-id]...]                    Abort a running workflow"
  echo -e
  echo -e "  Query workflow status:"
  echo -e "   status [workflow-id] [[workflow-id]...]                   Check the status of a workflow"
  echo -e "   metadata [workflow-id] [[workflow-id]...]                 Get the full metadata of a workflow"
  echo -e "   slim-metadata [workflow-id] [[workflow-id]...]            Get a subset of the metadata from a workflow"
  echo -e "   execution-status-count [workflow-id] [[workflow-id]...]   Get the summarized status of all jobs in the workflow"
  echo -e "   timing [workflow-id] [[workflow-id]...]                   Open the timing diagram in a browser"
  echo -e
  echo -e "  Logs"
  echo -e "   logs [workflow-id] [[workflow-id]...]                     List the log files produced by a workflow"
  echo -e "   fetch-logs [workflow-id] [[workflow-id]...]               Download all logs produced by a workflow"
  echo -e
  echo -e "  Job Outputs"
  echo -e "   list-outputs [workflow-id] [[workflow-id]...]             List all output files produced by a workflow"
  echo -e "   fetch-all [workflow-id] [[workflow-id]...]                Download all output files produced by a workflow"
  echo -e
  echo    "  Get email notification on job completion"
  echo -e "   notify [workflow-id] [daemon-server] email [cromwell-server]"
  echo -e "        daemon-server  server to run the notification daemon on"
  echo
  echo -e "  Display a list jobs submitted through cromshell:"
  echo -e "   list [-c] [-u]                                            "
  echo -e "         -c    Color the output by completion status"
  echo -e "         -u    Check completion status of all unfinished jobs"
  echo -e
  echo -e "Return values:"
  echo -e "  0                  SUCCESS"
  echo -e "  ANYTHING_BUT_ZERO  FAILURE/ERROR"
  echo
}

#Display a message to std error:
function error() 
{
  echo "$1" 1>&2 
}

TMPFILELIST=''
function makeTemp()
{
  local f
  f=$( mktemp )
  TMPFILELIST="${TMPFILELIST} $f"
  echo $f
}

function cleanTempVars()
{
  rm -f ${TMPFILELIST}
}

function at_exit()
{
  cleanTempVars
}

# Checks the bash built-in PIPESTATUS variable for any failures
# If given strings will output the string corresponding to the failure
# position in PIPESTATUS of any failures in the chain of commands 
# that occurred.
# This function should be called as `checkPipeStatus` as per the 
# alias below it.
function _checkPipeStatus()
{

  local hadFailure=false

  for (( i = 0 ; i < ${#RC[@]} ; i++ )) ; do 
    st=${RC[i]}
    if [ $st -ne 0 ] ; then
      # If we were passed a description string for this error in the pipe, then we print it:
      let argIndex=$i+1
      description=${!argIndex}
      [[ ${#description} -ne 0 ]] && error "$description"
      hadFailure=true  
    fi
  done

  if $hadFailure ; then
    return 10
  fi
  return 0
}
alias checkPipeStatus='RC=( "${PIPESTATUS[@]}" );_checkPipeStatus'

function checkPrerequisites
{
  local missing=""
  local foundMissing=false
  for c in ${@} ; do
    which $c &> /dev/null
    r=$?
    [[ $r -ne 0 ]] && foundMissing=true && missing="${missing}$c "
  done

  if $foundMissing ; then
    error "Error: the following commands could not be found:"
    error "  $missing"
    error "Please install them and try again."
    if [[ $(uname) == 'Darwin' ]] ; then
      error "NOTE: You likely must use homebrew to install them."
    fi
    return 1
  fi
  return 0
}


function assertCanCommunicateWithServer
{
  # Make sure we can talk to the cromwell server:
  serverName=$( echo ${1}| sed 's#.*://##g'| sed 's#:[0-9]*##g' )
  $PING_CMD $serverName &> /dev/null
  r=$?
  [[ $r -ne 0 ]] && error "Error: Cannot communicate with Cromwell server: $serverName" && exit 4
}

function assertHavePreviouslySubmittedAJob()
{
  local nLines=$( wc -l ${CROMWELL_SUBMISSIONS_FILE} | awk '{print $1}' )
  if [[ $nLines -eq 1 ]] ; then
    error "Error: You have never submitted any jobs using ${SCRIPTNAME}."
    error "       You must enter a workflow ID to get information on it."
    exit 99
  fi
}

################################################################################

trap at_exit EXIT 

################################################################################

function populateWorkflowIdAndServerUrl()
{
  local userSpecifiedId=$1
  
  # If the user specified a negative number, get the nth last workflow:
  if [[ $userSpecifiedId == -* ]]; then
    local row=${userSpecifiedId#-}
    assertHavePreviouslySubmittedAJob
    WORKFLOW_ID=$(tail -n $row $CROMWELL_SUBMISSIONS_FILE | head -n 1 | awk '{print $3}' )
    WORKFLOW_SERVER_URL=$(tail -n $row $CROMWELL_SUBMISSIONS_FILE | head -n 1 | awk '{print $2}' )
  else
    # If the user specified anything at this point, assume that it 
    # is a workflow UUID:
    if [ -n "$userSpecifiedId" ]; then 
      WORKFLOW_ID=$userSpecifiedId 
      WORKFLOW_SERVER_URL=${CROMWELL_URL}
  
      # Attempt to get the workflow server from the submission database:  
      local tmpFile=$( makeTemp )
      grep ${WORKFLOW_ID} ${CROMWELL_SUBMISSIONS_FILE} > ${tmpFile}
      r=$?
      [ $r -eq 0 ] && WORKFLOW_SERVER_URL=$( awk '{print $2}' ${tmpFile} )

    # If the user specified nothing, get the last workflow ID:  
    else
      assertHavePreviouslySubmittedAJob
      WORKFLOW_ID=$( tail -n1 ${CROMWELL_SUBMISSIONS_FILE} | awk '{print $3}' )
      WORKFLOW_SERVER_URL=$(tail -n1 $CROMWELL_SUBMISSIONS_FILE | awk '{print $2}' )
    fi
  fi
}

# Submit a workflow and arguments to the Cromwell Server

function submit() 
{
  turtle
  assertCanCommunicateWithServer $CROMWELL_URL

  local response=$(curl --connect-timeout $CURL_CONNECT_TIMEOUT -s -F workflowSource=@${1}  ${2:+ -F workflowInputs=@${2}} ${3:+ -F workflowOptions=@${3}} ${4:+ -F workflowDependencies=@${4}} ${CROMWELL_URL}/api/workflows/v1)
  local r=$?
  echo $response  

  [ $r -ne 0 ] && error "FAILED TO SUBMIT JOB" && return $r

  local id=$(echo $response | cut -d"," -f1 | cut -d":" -f2 | sed s/\"//g | sed s/\ //g)
  
  local runDir=${CROMSHELL_CONFIG_DIR}/${FOLDER_URL}/${id}
  mkdir -p ${runDir}

  cp ${1} ${2} ${3} ${4} ${runDir}/

  echo -e "$(date +%Y%m%d_%H%M%S)\t${CROMWELL_URL}\t${id}\t$(basename ${1})\tSubmitted" >> ${CROMWELL_SUBMISSIONS_FILE}

  return 0
}

# Check the status of a Cromwell job UUID
function status()
{

  local retVal=0

  assertCanCommunicateWithServer $2
  local f=$( makeTemp )
  curl --connect-timeout $CURL_CONNECT_TIMEOUT -s ${2}/api/workflows/v1/${1}/status > $f
  [[ $? -ne 0 ]] && error "Could not connect to Cromwell server." && return 2

  grep -qE '"Failed"|"Aborted"|"fail"' $f
  r=$?
  [[ $r -eq 0 ]] && retVal=1

  if [[ $retVal -eq 1 ]]; then
    turtleDead
  else
    turtle
  fi

  cat $f | jq . 
  checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."

  # Update ${CROMWELL_SUBMISSIONS_FILE}:
  local st=$( cat $f | jq . | grep status | sed -e 's#.*: ##g' | tr -d '",' )
  sed -i .bak -e "s#\\(.*${1}.*\\.wdl\\)\\t*.*#\\1$(printf '\t')${st}#g" ${CROMWELL_SUBMISSIONS_FILE}

  return $retVal
}

# Get the logs of a Cromwell job UUID
function logs() 
{
  turtle
  assertCanCommunicateWithServer $2
  curl --connect-timeout $CURL_CONNECT_TIMEOUT -s ${2}/api/workflows/v1/${1}/logs | jq . 
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the metadata for a Cromwell job UUID
function metadata() 
{
  turtle
  assertCanCommunicateWithServer $2
  curl --connect-timeout $CURL_CONNECT_TIMEOUT --compressed -s ${2}/api/workflows/v1/${1}/metadata?${CROMWELL_METADATA_PARAMETERS} | jq . 
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the metadata in condensed form for a Cromwell job UUID
function slim-metadata() 
{
  turtle
  assertCanCommunicateWithServer $2
  curl --connect-timeout $CURL_CONNECT_TIMEOUT --compressed -s "${2}/api/workflows/v1/$1/metadata?includeKey=executionStatus&includeKey=backendStatus&expandSubWorkflows=true" | jq .
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the status of the given job and how many times it was run
function execution-status-count() 
{
  turtle
  assertCanCommunicateWithServer $2
  f=$( makeTemp )
  curl --connect-timeout $CURL_CONNECT_TIMEOUT --compressed -s ${2}/api/workflows/v1/$1/metadata?${CROMWELL_METADATA_PARAMETERS} > $f
  [[ $? -ne 0 ]] && error "Could not connect to Cromwell server." && return 9

  # Make sure the query succeeded:
  if [[ "$( cat $f | jq '.status' | sed -e 's#^"##g' -e 's#"$##g' )" == 'fail' ]] ; then
    reason=$( cat $f | jq '.message' | sed -e 's#^"##g' -e 's#"$##g' )
    error "Error: Query to cromwell server failed: ${reason}"
    return 11
  fi

  # Make it pretty for the user:
  cat $f | jq '.calls | to_entries | map({(.key): .value | flatten | group_by(.executionStatus) | map({(.[0].executionStatus): . | length}) | add})'
  checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."
  return $?
}

# Bring up a browser window to view timing information on the job.
function timing() 
{
  turtle
  echo "Opening timing information in a web browser for job ID: ${1}"
  open ${2}/api/workflows/v1/${1}/timing
  return $?
}

# Cancel a running job.
function abort() 
{
  turtle
  assertCanCommunicateWithServer $2
  response=$(curl --connect-timeout $CURL_CONNECT_TIMEOUT -X POST --header "Content-Type: application/json" --header "Accept: application/json" "${2}/api/workflows/v1/${1}/abort")
  local r=$?
  echo $response  
  return $r
}

# List all jobs submitted in ${CROMWELL_SUBMISSIONS_FILE}
function list()
{
  turtle
  local doColor=false
  local doUpdate=false

  for arg in ${@} ; do 
    case "$arg" in
      -c) doColor=true
         ;; 
      -u) doUpdate=true
         ;; 
    esac
  done
 
  # If we need to update the data, do so here:
  if $doUpdate ; then
    error "Updating cached status list"
    local tmpFile srv id runSt 

    # Make a copy of our file because we'll be modifying it:
    tmpFile=$( makeTemp )
    cp ${CROMWELL_SUBMISSIONS_FILE} ${tmpFile}

    while read line ; do 
        id=$( echo "$line" | awk '{print $3}' )
        # Only update if the ID field is, in fact, a valid ID:
        if [[ "${id}" =~ ^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$ ]] ; then
          srv=$( echo "$line" | awk '{print $2}' )
          runSt=$( echo "$line" | awk '{print $5}' )
          
          # get the status of the run if it has not completed:
          if [[ "${runSt}" != "Failed" ]] && [[ "${runSt}" != "Aborted" ]] && [[ "${runSt}" != "Succeeded" ]] ; then
            status ${id} ${srv} &> /dev/null
          fi
        fi
    done < ${tmpFile}
  fi
 
  # If we have to colorize the output, we do so:
  if $doColor ; then

    local tmpFile=$( makeTemp )  
    cat ${CROMWELL_SUBMISSIONS_FILE} | column -t > ${tmpFile}

    while read line ; do 
  
      # Check for header line:
      echo "${line}" | grep -q '^DATE' 
      r=$?
      [ $r -eq 0 ] && echo -e "${COLOR_UNDERLINED}${line}${COLOR_NORM}" && continue

      # Check for failed jobs and color those lines:
      echo "${line}" | grep -q 'Failed' 
      r=$?
      [ $r -eq 0 ] && echo -e "${COLOR_FAILED}${line}${COLOR_NORM}" && continue

      # Check for successful jobs and color those lines:
      echo "${line}" | grep -q 'Succeeded' 
      r=$?
      [ $r -eq 0 ] && echo -e "${COLOR_SUCCEEDED}${line}${COLOR_NORM}" && continue

      # Check for running jobs and color those lines:
      echo "${line}" | grep -q 'Running' 
      r=$?
      [ $r -eq 0 ] && echo -e "${COLOR_RUNNING}${line}${COLOR_NORM}" && continue

      echo "${line}"  
    done < ${tmpFile} 
  else  
    cat ${CROMWELL_SUBMISSIONS_FILE} | column -t
  fi
  return $?
}

# List the output files for a given run.
# Will list all output files that are not:
#     *.log
#     rc
#     stdout
#     stderr
#     script
#     output
function list-outputs() 
{
  turtle
  assertCanCommunicateWithServer $2
  local id=$1
  local cromwellServer=$2

  local remoteFolder=$( metadata ${id} ${cromwellServer} | grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  which gsutil &>/dev/null   
  r=$?
  [ $r -ne 0 ] && error "gsutil does not exist.  Must install google cloud utilities." && exit 8

  error "Output files from job ${cromwellServer}:${id} : "

  # The -n flag just lists what would have happened if the copy occurred
  # we use this to our advantage to list the files we want:
  gsutil rsync -rP -n -x '.*\.[Ll][oO][Gg]$|.*rc|.*stdout|.*stderr|.*script|.*output' ${remoteFolder}/ ${localServerFolder}/. 2>&1 | \
    grep 'Would copy' | \
    sed 's#Would copy \(.*\) to .*#\1#g'

  return 0
}


# Get the root log folder from the cloud and put it in the metadata folder for this run
function fetch-logs() 
{
  turtle
  assertCanCommunicateWithServer $2
  local id=$1
  local cromwellServer=$2

  local remoteFolder=$( metadata ${id} ${cromwellServer} | grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  which gsutil &>/dev/null   
  r=$?
  [ $r -ne 0 ] && error "gsutil does not exist.  Must install google cloud utilities." && exit 8

  mkdir -p ${localServerFolder}

  error "Retrieving logs from ${remoteFolder}"
  error "Copying into ${localServerFolder}"

  # Do the copy, filtering for log files only:
  # Specifically, it will copy all files:
  #     - ending in .log (case insensitive)
  #     - Named rc
  #     - Named stdout
  #     - Named stderr
  #     - Named script
  gsutil rsync -rP -x '^(?!.*\.[Ll][oO][Gg]$|.*rc|.*stdout|.*stderr|.*script).*' ${remoteFolder}/ ${localServerFolder}/.

  error "Files copied to local folder: ${localServerFolder}"
  
  return 0
}

# Get the root log folder from the cloud and put it in the metadata folder for this run
# Includes all logs and output files
function fetch-all() 
{
  turtle
  assertCanCommunicateWithServer $2
  local id=$1
  local cromwellServer=$2

  local remoteFolder=$( metadata ${id} ${cromwellServer} | grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  which gsutil &>/dev/null   
  r=$?
  [ $r -ne 0 ] && error "gsutil does not exist.  Must install google cloud utilities." && exit 8

  mkdir -p ${localServerFolder}

  error "Retrieving logs from ${remoteFolder}"
  error "Copying into ${localServerFolder}"
  gsutil rsync -rP ${remoteFolder}/ ${localServerFolder}/.

  error "Files copied to local folder: ${localServerFolder}"
  
  return 0
}

# Spin off a task in the background that will check periodically if the workflow ID is 
# complete.
# When it is, send an email to the email address specified.
function notify()
{

  local id=$1
  local email=$2
  local cromwellServer=$3

  assertCanCommunicateWithServer ${cromwellServer}
  local separator="=================================================="
  
  while true ; do 
    completionStatus=$( status $id ${cromwellServer} 2>/dev/null | grep "status" | sed -e 's#.*status":##g' | tr -d ' ",' )
    echo $completionStatus | grep -qE "Succeeded|Failed|Aborted" 
    r=${PIPESTATUS[1]}
    if [ $r -eq 0 ] ; then
       workflowFile=$( grep '$id' ${CROMWELL_SUBMISSIONS_FILE} | head -n1 | awk '{print $4}' ) 
      metaData=$( metadata $id ${cromwellServer} )
      echo -e "CROMWELL Task ${completionStatus}:\n\n${id}\n\non\n\n${cromwellServer}\n\n${separator}\n\nStatus:\n$(cat ${statusFile})\n\n${separator}\nMetadata:\n${metaData}\n\n${separator}\nSent by $( whoami )@$( hostname ) on $( date ) \n\n\n" | mail -n -s "Cromwell Task ${completionStatus} [${cromwellServer}] ${workflowFile}" ${email} 
      break
    fi
    # wait for 10 seconds:
    sleep 10
  done 
}

function runSubCommandOnWorkflowId()
{
  # Get the workflow ID:
  populateWorkflowIdAndServerUrl $1
  error "Using workflow-id == $WORKFLOW_ID"
  error "Using workflow server URL == $WORKFLOW_SERVER_URL"
  ${SUB_COMMAND} ${WORKFLOW_ID} ${WORKFLOW_SERVER_URL} 
  r=$?
  echo
  return $r
}

################################################################################

# Do all the interactive stuff if the script is called by a user.
# The bash equivalent to `if __name__ == '__main__':
if ${ISCALLEDBYUSER} ; then

  #Check given arguments:
  if [[ $# -gt $MAXARGS ]] ; then
    simpleUsage
    exit 1
  elif [[ $# -lt $MINARGS ]] ; then
    simpleUsage
    exit 2
  fi

  #Read args:
  while [ $# -gt 0 ] ; do

    case "$1" in
      -h|--h|--help|-help|help)
        usage;
        exit 0;
        ;;
      submit|status|logs|execution-status-count|metadata|slim-metadata|timing|abort|notify|list|fetch-all|fetch-logs|list-outputs) 
        # Get our sub-command:
        SUB_COMMAND=$1
        shift
        # We'll manually handle the rest of the options:
        break
        ;;
      *)
        error "${SCRIPTNAME}: invalid option: $1" 
        simpleUsage
        echo "Try \`$SCRIPTNAME --help' for more information."
        exit 3;
        ;; 
    esac

    #Get next argument in $1:
    shift
  done

  ################################################################################

  # Make sure we have all the required commands:
  checkPrerequisites $PREREQUISITES 
  r=$?
  [[ $r -ne 0 ]] && exit 6

  # Special case: submitting a job:
  if [[ "${SUB_COMMAND}" == "submit" ]] ; then
    ${SUB_COMMAND} $1 $2 $3 $4 
    exit $?
  fi

  # Special case: list
  if [[ "${SUB_COMMAND}" == "list" ]] ; then
    ${SUB_COMMAND} $1 $2
    exit $?
  fi
  
  # Special case: notify
  if [[ "${SUB_COMMAND}" == "notify" ]] ; then
    turtle
    # Is the next argument our workflow ID?
    # Workflow IDs are standard UUIDs:
    if [[ "${1}" =~ ^[0-9a-fA-F]{8}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{4}-[0-9a-fA-F]{12}$ ]] ; then
      # Get the workflow ID:
      populateWorkflowIdAndServerUrl $1
      shift
    fi
 
    # Get the host on which this will be run:
    hostServer="${HOSTNAME}"
    
    if [[ ! "${1}" =~ ^.*@.*  ]] ; then
      hostServer=$1
      shift
    fi

    # Make sure the user gave us a good email address:
    echo "$1" | grep -q  '@' 
    r=$?
    [ $r -ne 0 ] && error "Error: invalid email address: $1" && exit 5
    email=$1

    # Make sure our workflow ID is populated:
    populateWorkflowIdAndServerUrl ${WORKFLOW_ID}

    # Do some wizardry here to spin off the notification daemon on a remote server:
    if [[ "${hostServer}" != "${HOSTNAME}" ]] ; then
      error "Creating notification daemon on host ${hostServer} ..."

      # Send the script to the server:
      scp ${SCRIPTDIR}/${SCRIPTNAME} ${hostServer}:~/. &> /dev/null
      [[ $? -ne 0 ]] && error "ERROR: Could not copy cromshell to server ${hostServer}" && exit 7

      # Spin off notification process on the server:
      results=$( ssh ${hostServer} "~/${SCRIPTNAME} notify ${WORKFLOW_ID} ${email} ${WORKFLOW_SERVER_URL}" )
      [[ $? -ne 0 ]] && error "ERROR: Could not start notification daemon on ${hostServer}" && exit 8

      # Let the user know we've done our job:
      echo "Spun off thread on ${hostServer} - PID = $( echo "${results}" | grep "Spun off thread on PID" | sed 's#Spun off thread on PID ##g' )"
    else
      error "Spinning off notification to ${email} thread for workflow ${WORKFLOW_ID} ..."
      nohup bash -c "source ${SCRIPTDIR}/${SCRIPTNAME}; notify ${WORKFLOW_ID} ${email} ${WORKFLOW_SERVER_URL}" &>/dev/null &
      echo "Spun off thread on PID $!"
    fi

    exit 0
  fi

  # Run our sub command once on the first workflow ID:
  runSubCommandOnWorkflowId ${1}
  r=$?
  shift

  # Run the task on all remaining workflow IDs:
  # This is required because there's no do-while loop in bash.
  while [ $# -gt 0 ] ; do
    runSubCommandOnWorkflowId ${1}
    r=$?
    shift
  done

  # Exit the script with the return value of the last run sub-command:
  exit $r

fi

