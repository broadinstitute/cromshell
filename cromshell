#!/usr/bin/env bash

################################################################################

# Setup variables for the script:
UNALIASED_SCRIPT_NAME=$( python -c "import os;print (os.path.realpath(\"${BASH_SOURCE[0]}\"))" )
SCRIPTDIR="$( cd "$( dirname "${UNALIASED_SCRIPT_NAME}" )" && pwd )"
SCRIPTNAME=$( echo $0 | sed 's#.*/##g' )
MINARGS=1
MAXARGS=99
PREREQUISITES="curl jq mail column tput rev base64 gunzip"

# Determine if this shell is interactive:
ISINTERACTIVESHELL=true
[[ "${BASH_SOURCE[0]}" != "${0}" ]] && ISINTERACTIVESHELL=false

# Required for the aliased call to checkPipeStatus:
shopt -s expand_aliases

################################################################################

COLOR_NORM='\033[0m'
COLOR_UNDERLINED='\033[1;4m'
COLOR_FAILED='\033[1;37;41m'
COLOR_DOOMED='\033[1;31;47m'
COLOR_SUCCEEDED='\033[1;30;42m'
COLOR_RUNNING='\033[0;30;46m'
COLOR_ABORTED='\033[0;30;43m'

TASK_COLOR_RUNNING='\033[0;34m'
TASK_COLOR_SUCCEEDED='\033[0;32m'
TASK_COLOR_FAILING='\033[0;33m'
TASK_COLOR_FAILED='\033[0;31m'

################################################################################

DOOMED_LOGO_b64gz="H4sIAOfW3l0AA6WUwXHEIAxF767i35yDQQUkTiWeYcvIgUPa2GbSwHaRSiIJAcL2zmTHeGKYj/QQ39qs625Axv+0vqyrabOB6J+mAkQv79TVIBNpGNGUs24kGbrKGV47Gz2uH1aArE5F5TcM1CKJtWURN8q7Tsi1wH54e5Roe0CDd01yf79/ZFoC8YrES10UvMuRlM4+FpuChoVkmt5s/WDW5+4Vln1KzMOn29cdZpgT2G5BRcKbK56nLEW7Pyt/SNVTklbtrpCqO2ih8O58ER73ObzzMz/uQDXGhZfyubZEudaf+GjZjJkGsoTmJ90xhmaUNiSoRVqubgsaA1SNSYc7HAIdUg2pzO1mgSO07/TyTyIHKhq0jsg9NXMiT3EU45kIEsn8J5wwo0SV/SQNZ5SSDf6gSQt1IncamfaMa1CYZ+KnJjixaFX1Gp2Xu2P2L5X0V+tlUSOlUeIOispu0FPiC0OZUIuZdxFWmeXi6u5k/1MvIkup6jZN3CXzZVplMitOf/Lm5/B8BgAA"

################################################################################

# Setup Cromshell config details:
CROMSHELL_CONFIG_DIR=${HOME}/.cromshell
mkdir -p ${CROMSHELL_CONFIG_DIR}
CROMWELL_SUBMISSIONS_FILE="${CROMSHELL_CONFIG_DIR}/all.workflow.database.tsv"
[[ ! -f ${CROMWELL_SUBMISSIONS_FILE} ]] && echo -e "DATE\tCROMWELL_SERVER\tRUN_ID\tWDL_NAME\tSTATUS\tALIAS" > ${CROMWELL_SUBMISSIONS_FILE}

# Set the GCP big query cost table file:
BQ_COST_TABLE_FILE=${CROMSHELL_CONFIG_DIR}/gcp_bq_cost_table.config

# Update cromshell submissions file if it needs updating:
grep -q 'ALIAS$' ${CROMWELL_SUBMISSIONS_FILE} 
r=$?
if [[ $r -ne 0 ]] ; then
  echo "Upgrading cromshell config file..." 1>&2
  cp ${CROMWELL_SUBMISSIONS_FILE} ${CROMSHELL_CONFIG_DIR}/tmp.tmptmp
  echo -e "DATE\tCROMWELL_SERVER\tRUN_ID\tWDL_NAME\tSTATUS\tALIAS" > ${CROMWELL_SUBMISSIONS_FILE}
  tail -n+2 ${CROMSHELL_CONFIG_DIR}/tmp.tmptmp >> ${CROMWELL_SUBMISSIONS_FILE}
  rm ${CROMSHELL_CONFIG_DIR}/tmp.tmptmp
fi

# Find the CROMWELL Server:
CROMWELL_SERVER_FILE=${CROMSHELL_CONFIG_DIR}/cromwell_server.config
CROMWELL_NEEDS_SETUP=true
[[ -f ${CROMWELL_SERVER_FILE} ]] && CROMWELL_NEEDS_SETUP=false
if ! ${CROMWELL_NEEDS_SETUP} ; then
  # NOTE: Server file allows for line comments using the prefix `#`
  CROMWELL_SERVER_FROM_FILE=$( grep -v '^#' ${CROMWELL_SERVER_FILE} | head -n1 )
fi

# read env var, or use default server URL
export CROMWELL_URL=${CROMWELL_URL:-"${CROMWELL_SERVER_FROM_FILE}"}
FOLDER_URL=$( echo ${CROMWELL_URL} | sed -e 's#ht.*://##g' ) 
CROMWELL_METADATA_PARAMETERS="excludeKey=submittedFiles&expandSubWorkflows=true"
# broken into two lines to ensure that users with custom CROMWELL_SLIM_METADATA_PARAMETERS will still have subworkflow metadata available in the outputs
CROMWELL_SLIM_METADATA_PARAMETERS="${CROMWELL_SLIM_METADATA_PARAMETERS:-includeKey=id&includeKey=executionStatus&includeKey=backendStatus&includeKey=status&includeKey=callRoot&expandSubWorkflows=true}"
CROMWELL_SLIM_METADATA_PARAMETERS+="&includeKey=subWorkflowMetadata&includeKey=subWorkflowId"

CURL_CONNECT_TIMEOUT=5
let CURL_MAX_TIMEOUT=2*${CURL_CONNECT_TIMEOUT}

# CROMSHELL_HEADER can be set externally and can be use to pass things like oauth tokens to curl...
if [[ -z "${CROMSHELL_HEADER}" ]]; then
  alias curl='curl --connect-timeout ${CURL_CONNECT_TIMEOUT} --max-time ${CURL_MAX_TIMEOUT}'
else
  alias curl='curl -H "${CROMSHELL_HEADER}" --connect-timeout ${CURL_CONNECT_TIMEOUT} --max-time ${CURL_MAX_TIMEOUT}'
fi

################################################################################

SUB_COMMAND=''
WORKFLOW_ID_LIST=''
WORKFLOW_ID=''
WORKFLOW_SERVER_URL=''
OPTIONS=''

TERMINAL_STATES="Succeeded Failed Aborted"

################################################################################

function doomedLogo() 
{
  # Figure out which decoder to use:
  base64 -D <<<"MQo=" &> /dev/null
  r=$?
  if [[ $r -eq 0 ]] ; then
    base64 -D <<<"${DOOMED_LOGO_b64gz}" | gunzip
  else
    base64 -d <<<"${DOOMED_LOGO_b64gz}" | gunzip
  fi | while read line ; do 
    error "${COLOR_FAILED}${line}${COLOR_NORM}"
  done
}

function turtle() 
{
  error "                  __     "
  error "       .,-;-;-,. /'_\\    "
  error "     _/_/_/_|_\\_\\) /     "
  error "   '-<_><_><_><_>=/\\     "
  error "     \`/_/====/_/-'\\_\\    " 
  error "      \"\"     \"\"    \"\"    " 
}

function turtleDead()
{
  error "${COLOR_FAILED}    ,,    ,,     ,,      ${COLOR_NORM}"
  error "${COLOR_FAILED}    \\‾\\,-/‾/====/‾/,     ${COLOR_NORM}"
  error "${COLOR_FAILED}     \\/=<‾><‾><‾><‾>-,   ${COLOR_NORM}"
  error "${COLOR_FAILED}     / (\\‾\\‾|‾/‾/‾/‾     ${COLOR_NORM}"
  error "${COLOR_FAILED}    \\‾x/ ˙'-;-;-'˙       ${COLOR_NORM}"
  error "${COLOR_FAILED}     ‾‾                  ${COLOR_NORM}"
}

################################################################################

function simpleUsage()
{
  if [[ $# -ne 0 ]] ; then
    usage | grep "  ${1} " | sed -e 's#\(.*]\).*#\1#g' -e "s#^[ \\t]*#Usage:    ${SCRIPTNAME} #g"
  else
    echo -e "Usage:    ${SCRIPTNAME} [-t TIMEOUT] SUB-COMMAND [options]"
    echo -e "Run and inspect workflows on a Cromwell server."
  fi
}

#Define a usage function:
function usage() 
{
  simpleUsage
  echo -e ""
  echo -e "CROMWELL_URL=${CROMWELL_URL}"
  echo -e ""
  echo -e "If no workflow-id is specified then the last submitted workflow-id is assumed."
  echo -e "Alternatively, negative numbers can be used to refer to previous workflows."
  echo -e ""
  echo -e "  example usage:"
  echo -e "      cromshell submit workflow.wdl inputs.json options.json dependencies.zip"
  echo -e "      cromshell status"
  echo -e "      cromshell -t 50 status"
  echo -e "      cromshell logs -2"
  echo -e ""
  echo -e "Environment Variables:"
  echo -e "  CROMSHELL_HEADER       Can be use to pass things like oauth tokens to the request header"
  echo -e ""
  echo -e "Supported Flags:"
  echo -e "  -t TIMEOUT             Set the curl connect timeout to TIMEOUT seconds."
  echo -e "                         Also sets the curl max timeout to 2*TIMEOUT seconds."
  echo -e "                         TIMEOUT must be an integer."
  echo -e ""
  echo -e "Supported Subcommands:"
  echo -e ""
  echo -e "  Start/Stop workflows:"
  echo -e "   submit [-w] <wdl> <inputs_json> [options_json] [included_wdl_zip_file] Submit a new workflow"
  echo -e "        -w                     Wait for workflow to transition from 'Submitted' to some other status"
  echo -e "                               before ${SCRIPTNAME} exits"
  echo -e "        included_wdl_zip_file  Zip file containing any WDL files included in the input WDL"
  echo -e ""
  echo -e "   abort [workflow-id] [[workflow-id]...]                            Abort a running workflow."
  echo -e
  echo -e "  Workflow information:"
  echo -e
  echo -e "   alias workflow-id alias                                           Label the given workflow ID with the given alias."
  echo -e "                                                                     Aliases can be used in place of workflow IDs to reference"
  echo -e "                                                                     jobs."
  echo -e
  echo -e "  Query workflow status:"
  echo -e "   status [workflow-id] [[workflow-id]...]                           Check the status of a workflow."
  echo -e "   metadata [workflow-id] [[workflow-id]...]                         Get the full metadata of a workflow."
  echo -e "   slim-metadata [workflow-id] [[workflow-id]...]                    Get a subset of the metadata from a workflow."
  echo -e "   execution-status-count, counts [-p] [-x] [workflow-id] [[workflow-id]...] Get the summarized status of all jobs in the workflow."
  echo -e "         -p               Enable pretty-printing."
  echo -e "         -x               Expand sub-workflow information."
  echo -e "   timing [workflow-id] [[workflow-id]...]                           Open the timing diagram in a browser."
  echo -e
  echo -e "  Logs:"
  echo -e "   logs [workflow-id] [[workflow-id]...]                             List the log files produced by a workflow."
  echo -e "   fetch-logs [workflow-id] [[workflow-id]...]                       Download all logs produced by a workflow."
  echo -e
  echo -e "  Job Outputs:"
  echo -e "   list-outputs [workflow-id] [[workflow-id]...]                     List all output files produced by a workflow."
  echo -e "   fetch-all [workflow-id] [[workflow-id]...]                        Download all output files produced by a workflow."
  echo -e
  echo -e "  Get email notification on job completion:"
  echo -e "   notify [workflow-id] [daemon-server] email [cromwell-server]"
  echo -e "        email             Email address to which to send the notification."
  echo -e "        daemon-server     Server on which to run the notification daemon."
  echo -e ""
  echo -e "  Display a list jobs submitted through cromshell:"
  echo -e "   list [-c] [-u]                                            "
  echo -e "         -c               Color the output by completion status."
  echo -e "         -u               Check completion status of all unfinished jobs."
  echo -e "" 
  echo -e "  Clean up local cached list:"
  echo -e "   cleanup [-s STATUS]    Remove completed jobs from local list."
  echo -e "                          Will remove all jobs from the local list that are in a completed state,"
  echo -e "                          where a completed state is one of: $(echo ${TERMINAL_STATES} | tr ' ' ',' )" 
  echo -e "         -s STATUS        If provided, will only remove jobs with the given STATUS from the local list."
  echo -e "  Update cromwell server:"
  echo -e "   update-server          Change which cromwell server jobs will be submitted to."
  echo -e ""
  echo -e "  Get cost for a workflow"
  echo -e "   cost [workflow-id] [[workflow-id]...]                  Get the cost for a workflow."
  echo -e "                                                          Only works for workflows that completed"
  echo -e "                                                          more than 8 hours ago on GCS."
  echo -e "                                                          Requires the 'gcp_bq_cost_table.config'"
  echo -e "                                                          configuration file to exist and contain"
  echo -e "                                                          the big query cost table for your organization."
  echo -e "   cost-detailed [workflow-id] [[workflow-id]...]         Get the cost for a workflow at the task level."
  echo -e "                                                          Only works for workflows that completed"
  echo -e "                                                          more than 8 hours ago on GCS."
  echo -e "                                                          Requires the 'gcp_bq_cost_table.config'"
  echo -e "                                                          configuration file to exist and contain"
  echo -e "                                                          the big query cost table for your organization."
  echo -e ""
  echo -e "Return values:"
  echo -e "  0                  SUCCESS"
  echo -e "  ANYTHING_BUT_ZERO  FAILURE/ERROR"
  echo
}

#Display a message to std error:
function error() 
{
  echo -e "${1}" 1>&2
}

# Make a better temp file that gets cleaned up on script exit:
TMPFILELIST=''
function makeTemp()
{
  local f
  f=$( mktemp )
  TMPFILELIST="${TMPFILELIST} ${f}"
  echo ${f}
}

# Function to clean our temp files:
function cleanTempVars()
{
  rm -f ${TMPFILELIST}
}

# Track the given subprocess in our list so we can kill it when we exit.
SUBPROCESSLIST=''
function trackSubProcess() 
{
  SUBPROCESSLIST="${SUBPROCESSLIST} ${1}"
}

# Function to kill subprocesses created by this script.
function killSubProcesses()
{
  # Disown the subprocesses so we don't see the kill message on exit:
  [[ ${#SUBPROCESSLIST} -gt 0 ]] && disown ${SUBPROCESSLIST} &> /dev/null

  # Kill them dead if they're still running:
  [[ ${#SUBPROCESSLIST} -gt 0 ]] && kill -9 ${SUBPROCESSLIST} &> /dev/null
}

# Function to be called at exit:
function at_exit()
{
  cleanTempVars
  killSubProcesses
}
# Make sure we clean up on exit:
trap at_exit EXIT 

# Print the name and value of a simple variable:
function printVar()
{
  error "${1} = ${!1}"
}

# Checks the bash built-in PIPESTATUS variable for any failures
# If given strings will output the string corresponding to the failure
# position in PIPESTATUS of any failures in the chain of commands 
# that occurred.
# This function should be called as `checkPipeStatus` as per the 
# alias below it.
function _checkPipeStatus()
{
  local hadFailure=false

  for (( i = 0 ; i < ${#RC[@]} ; i++ )) ; do 
    st=${RC[i]}
    if [[ ${st} -ne 0 ]] ; then
      # If we were passed a description string for this error in the pipe, then we print it:
      let argIndex=$i+1
      description=${!argIndex}
      [[ ${#description} -ne 0 ]] && error "${description}"
      hadFailure=true  
    fi
  done

  if ${hadFailure} ; then
    return 10
  fi
  return 0
}
alias checkPipeStatus='RC=( "${PIPESTATUS[@]}" );_checkPipeStatus'

function checkPrerequisites
{
  local missing=""
  local foundMissing=false
  for c in ${@} ; do
    which ${c} &> /dev/null
    r=$?
    [[ ${r} -ne 0 ]] && foundMissing=true && missing="${missing}${c} "
  done

  if ${foundMissing} ; then
    error "Error: the following commands could not be found:"
    error "  $missing"
    error "Please install them and try again."
    if [[ $(uname) == 'Darwin' ]] ; then
      error "NOTE: You likely must use homebrew to install them."
    fi
    return 1
  fi
  return 0
}

function checkJQVersion() {
 #With thanks to https://unix.stackexchange.com/a/285928/167681
 local currentVersion="$( jq --version )"
 local requiredVersion="jq-1.5"
 if [ "$(printf '%s\n' "$requiredVersion" "$currentVersion" | sort -V | head -n1)" = "$requiredVersion" ]; then
       return 0
 else
       error "ERROR: jq version must be at least ${requiredVersion}, you have ${currentVersion}."
       return 1
 fi
}

function assertRequiredFileIsNonEmpty()
{
  local fileName=${1}
  local fileDescription=${2}
  if [[ -z ${fileName} ]]; then
    error "ERROR: ${fileDescription} must be specified."
  exit 6
  else
    if [[ -f ${fileName} ]]; then
      if [[ ! -s ${fileName} ]]; then
        error "ERROR: ${fileDescription} is empty: ${fileName}"
        exit 6
      fi
    else
      error "ERROR: ${fileDescription} does not exist: ${fileName}"
      exit 6;
    fi
  fi
}

function assertOptionalFileIsNonEmpty()
{
  local fileName=${1}
  local fileDescription=${2}
  if [[ ! -z ${fileName} ]] ; then
    assertRequiredFileIsNonEmpty "${fileName}" "${fileDescription}"
  fi
}

function checkForComplexHelpArgument()
{
  for arg in $@ ; do
    case ${arg} in
      -h|--h|-\?|--\?|--help|-help|help) usage; exit 0;;
    esac
  done
}

################################################################################
# Cromshell-specific Utility Functions:

# Handle arguments just expecting workflow IDs:
# Will populate the $WORKFLOW_ID_LIST global variable or exit.
function extract_workflow_ids_from_args()
{
  #Read args:
  if [[ $# -eq 0 ]] ; then
    # No specified workflow ID.
    # Get the last one.
    populateLastWorkflowId
    WORKFLOW_ID_LIST="${WORKFLOW_ID}"
  else
    while [[ $# -gt 0 ]] ; do
      populateWorkflowIdAndServerUrl ${1}
      WORKFLOW_ID_LIST="${WORKFLOW_ID_LIST} ${WORKFLOW_ID}"

      #Get next argument in ${1}:
      shift
    done
  fi
}

function matchRelativeWorkflowId() 
{
  local rv=1

  if [[ "${1}" =~ ^-[[:xdigit:]]*$ ]] ; then
    rv=0
  fi

  echo ${rv}
  return ${rv}
}

function matchWorkflowId() 
{
  local rv=1

  if [[ "${1}" =~ ^[[:xdigit:]]{8}-[[:xdigit:]]{4}-[[:xdigit:]]{4}-[[:xdigit:]]{4}-[[:xdigit:]]{12}$ ]] ; then
    rv=0
  fi

  echo ${rv}
  return ${rv}
}

function invalidSubCommand()
{
  error "${SCRIPTNAME} ${1}: invalid ${2}: ${3}"
  error ""
  if [[ ${#1} -eq 0 ]] ; then
    simpleUsage
  else
    simpleUsage ${1}
  fi
  echo "Try \`${SCRIPTNAME} -h' for more information."
  exit 3;
}

function getAnswerFromUser()
{
  local prompt="${1}" 
  local acceptableValues="${2}"
  local responseVar="${3}" 

  local haveGoodValue=false
  while ! ${haveGoodValue} ; do
    read -p "${prompt} [$( echo ${acceptableValues} | tr ' ' '/' )] : " ${responseVar}

    for okVal in ${acceptableValues} ; do
      if [[ "$( echo ${!responseVar} | tr a-z A-Z)" == "$( echo ${okVal} | tr a-z A-Z)" ]] ; then
        haveGoodValue=true
      fi
    done

    ! ${haveGoodValue} && error "Please enter one of the following: $( echo ${acceptableValues} | tr ' ' '/' )" && error ""
  done
}

function assertCanCommunicateWithServer
{
  # Make sure we can talk to the cromwell server:
  local f=$(makeTemp)
  curl -s ${1}/api/workflows/v1/backends > ${f}  
  grep -q 'supportedBackends' ${f}
  r=$?
  # Do some cleanup here for daemon processes.
  rm -f ${f}
  if [[ ${r} -ne 0 ]] ; then
    turtleDead 
    error "Error: Cannot communicate with Cromwell server: ${serverName}"
    exit 4
  fi
}

function assertHavePreviouslySubmittedAJob()
{
  local nLines=$( wc -l ${CROMWELL_SUBMISSIONS_FILE} | awk '{print $1}' )
  if [[ ${nLines} -eq 1 ]] ; then
    error "Error: You have never submitted any jobs using ${SCRIPTNAME}."
    error "       You must enter a workflow ID to get information on it."
    exit 99
  fi
}

function populateLastWorkflowId() 
{
  assertHavePreviouslySubmittedAJob
  WORKFLOW_ID=$( tail -n1 ${CROMWELL_SUBMISSIONS_FILE} | awk '{print $3}' )
}

function aliasExists(){
  alias_name=${1}
  grep -q "\\t${alias_name}\$" ${CROMWELL_SUBMISSIONS_FILE}
}

function alias_workflow() 
{
  local alias_name=${2}

  # Check that we have an alias and workflow defined:
  if [[ ${#alias_name} -eq 0 ]] || [[ ${#1} -eq 0 ]] ; then
    error "ERROR: Cannot process alias name."
    error "       Please specify both a workflow ID and an alias."
    return 1
  fi

  if [[ ${alias_name} =~ ^-.* || ${alias_name} =~ [[:space:]]+ ]]; then
    error "Alias \"${alias_name}\" is invalid, it may not start with a dash or contain whitespace"
    return 1
  fi
  
  if aliasExists ${alias_name} ; then
    error "ERROR: Alias already exists: ${alias_name}"
    error "       Please choose another alias."
    return 1
  fi

  # Get the workflow ID:
  populateWorkflowIdAndServerUrl ${1}

  error "Aliasing ${WORKFLOW_ID} -> ${alias_name}"
  cp ${CROMWELL_SUBMISSIONS_FILE} ${CROMWELL_SUBMISSIONS_FILE}.bak
  awk "BEGIN { FS=OFS=\"\t\" } { if (\$3 == \"${WORKFLOW_ID}\") { \$6=\"${alias_name}\"; print} else {print;} }" ${CROMWELL_SUBMISSIONS_FILE}.bak > ${CROMWELL_SUBMISSIONS_FILE} 
  local r=$? 
  if [[ $r -eq 0 ]] ; then
    error "Done."
  else 
    error "Unable to create alias: ${WORKFLOW_ID} -> ${alias_name}"
  fi

  return $r
}

function populateWorkflowIdAndServerFromAlias()
{
    local alias_name=${1}
    WORKFLOW_ID=$(awk "BEGIN{FS=\"\t\"}{if (\$6 == \"${alias_name}\") {print}}" ${CROMWELL_SUBMISSIONS_FILE} | head -n1 | awk '{print $3}')
    WORKFLOW_SERVER_URL=$(awk "BEGIN{FS=\"\t\"}{if (\$6 == \"${alias_name}\") {print}}" ${CROMWELL_SUBMISSIONS_FILE} | head -n1 | awk '{print $2}')

    if [[ -z ${WORKFLOW_ID} ]]; then
      error "Invalid workflow/alias: ${alias_name}"
      exit 5
    fi
}

function populateWorkflowIdAndServerUrl()
{
  local userSpecifiedId=${1}

  # If the user specified relative workflow ID:
  if [[ $(matchRelativeWorkflowId ${userSpecifiedId}) -eq 0 ]] ; then 
    local row=${userSpecifiedId#-}
    assertHavePreviouslySubmittedAJob
    WORKFLOW_ID=$(tail -n ${row} ${CROMWELL_SUBMISSIONS_FILE} | head -n 1 | awk '{print $3}' )
    WORKFLOW_SERVER_URL=$(tail -n ${row} ${CROMWELL_SUBMISSIONS_FILE} | head -n 1 | awk '{print $2}' )
  elif [[ $(matchWorkflowId ${userSpecifiedId}) -eq 0 ]] ; then
      WORKFLOW_ID=${userSpecifiedId}
      WORKFLOW_SERVER_URL=${CROMWELL_URL}

      # Attempt to get the workflow server from the submission database:  
      local tmpFile=$( makeTemp )
      grep ${WORKFLOW_ID} ${CROMWELL_SUBMISSIONS_FILE} > ${tmpFile}
      r=$?
      [[ ${r} -eq 0 ]] && WORKFLOW_SERVER_URL=$( awk '{print $2}' ${tmpFile} )

      # Do some cleanup here for daemon processes.
      rm -f  ${tmpFile}
 else
    if [[ -n "$userSpecifiedId" ]]; then
      populateWorkflowIdAndServerFromAlias ${userSpecifiedId}
    else
      # If the user specified nothing, get the last workflow ID:  
      populateLastWorkflowId
      WORKFLOW_SERVER_URL=$(tail -n1 ${CROMWELL_SUBMISSIONS_FILE} | awk '{print $2}' )
    fi
  fi

  # Validate our workflow ID:
  if [[ $( matchWorkflowId ${WORKFLOW_ID} ) -ne 0 ]] ; then
    if [[ -n "${userSpecifiedId}" ]] ; then
      error "Invalid workflow ID: ${1}"
      error "It is likely that there are not this many records in your cromshell file."
    else
      error "Invalid workflow ID: ${WORKFLOW_ID}"
    fi
    exit 5
  fi
}

function _turtleSpinner()
{
  # Require a flag file to be given to this function.
  # This keeps it safe.
  if [[ $# -ne 1 ]] ; then
    return 1
  fi

  local flagFile=${1}

  # Let's be fancy and make turtles that are walking while we wait:
  local tmpTurtFile=$( makeTemp )
  local turtFile=$( makeTemp )
  local turtRFile=$( makeTemp )
  turtle &> ${tmpTurtFile}
  sed 's#^  ##g' ${tmpTurtFile} > ${turtFile}
  #Since we're switching pairs characters we need to do the switch in several steps
  #ex: /\ -> TMP\ -> TMP/ -> \/
  rev ${turtFile} | sed -e 's#/#TMP#g' -e 's#\\#/#g' -e 's#TMP#\\#g' \
      -e 's#(#TMP#g' -e 's#)#(#g' -e 's#TMP#)#g' \
      -e 's#>#TMP#g' -e 's#<#>#g' -e 's#TMP#<#g' > ${turtRFile}

  # Set up some loop variables:
  local i=3
  local incrementString="+1"
  local curTurtFile=${turtFile}

  # Let's loop while the ${flagFile} exists.
  # Note that this will be spun off into its own thread:
  while [[ -f ${flagFile} ]] ; do
    # Create padding for turtle:
    padding=$( printf "%${i}s" "" )

    # Display our turtle, moved a little to the right:
    cat ${curTurtFile} | sed -e "s#^#${padding}#g"
    sleep 0.1

    # Move the cursor back up to the top line of the turtle
    # so we create the illusion of movement:
    tput cuu 6

    # Now we update our loop variables in a clever way
    # so that the turtle will go back and forth.
    let i=i${incrementString}
    if [[ ${i} -eq 15 ]] ; then
      incrementString="-1" 
      curTurtFile=${turtRFile}
    elif [[ ${i} -eq 0 ]] ; then
      incrementString="+1" 
      curTurtFile=${turtFile}
    fi

  done & # The & here spins this off as a background thread/process

  # Track the sub-process so we can kill it if we exit early:
  trackSubProcess $!
}

function waitOnSubmittedStatus() 
{
  local id=${1}
  local cromwellServerUrl=${2}

  echo "Waiting on status to progress from 'Submitted' ..."
  echo

  # Use tput to save the cursor position:
  tput sc

  # The turtle starts 9 rows above where the cursor is at this point,
  # so if we need to move it, we have to move the cursor there before
  # we output anything:
  tput cuu 9

  # Reserve the name for a file whose non-existence will cause 
  # the following loop to exit.
  # This is good because all temp files made with `makeTemp` 
  # are automatically removed at exit, so this sub-process
  # will always die gracefully.
  local flagFile=$(makeTemp)
  echo 'TEST' > ${flagFile}

  # Kick off a turtle spinner...
  _turtleSpinner ${flagFile}

  # Now we check the status periodically and if we get a new one
  # Other than `Submitted` we can tell the other process to finish.
  local gotNewStatus=false
  local isDone=false
  local nChecks=0
  local statusFile=$( makeTemp )
  local r
  while ! ${isDone} ; do
    # Wait for a little bit so we don't kill the server:
    sleep 2

    # Check the status of our last submission:
    status ${id} ${cromwellServerUrl} &> ${statusFile}
    r=$?  
    grep -q '^[ \t]*"status": "Submitted",' ${statusFile}

    # We could no longer field the status as `Submitted`, so we're done.
    if [[ $? -eq 1 ]] && [[ ${r} -ne 2 ]] ; then
      gotNewStatus=true
    fi

    # Check if our status changed yet:   
    if ${gotNewStatus} ; then
      isDone=true
 
      # Delete the flag file to end the display process:
      rm -f ${flagFile}

      # Wait for the _turtleSpinner to exit:
      wait

      # Clear out the lines from our fancy animation:
      tput el;echo;tput el;echo;tput el;echo;tput el;echo;tput el;echo;tput el;echo;tput el;echo;tput el;echo
      tput cuu 8

      # Display the status file:
      cat ${statusFile} | sed 's#^Using ##g'
  
    # If we have waited too long, then we quit:
    elif [[ ${nChecks} -ge 10 ]] ; then
      isDone=true
      
      # Delete the flag file to end the display process:
      rm -f ${flagFile}
      
      # Wait for the _turtleSpinner to exit:
      wait

      echo "{\"id\":\"${id}\",\"status\":\"Submitted\"}"
      error "WARNING: Could not validate submission status with server.  Try again later."
      break
    fi

    let nChecks=${nChecks}+1
  done

  # Restore cursor position:
  tput rc
  
  # Add a line for padding:
  echo
  
  # Send a proper return code:
  if ${gotNewStatus} ; then
    return 0
  else
    return 1
  fi
}

# Submit a workflow and arguments to the Cromwell Server
function submit() 
{
  local doWait=false
    
  # Handle Arguments:
  local OPTIND
  while getopts "w" opt ; do
    case ${opt} in 
      w)
        doWait=true
        ;;
      *)
        invalidSubCommand submit flag ${OPTARG}
        ;; 
    esac 
  done
  shift $((OPTIND-1)) 
 
  # ----------------------------------------

  if [[ $# -lt 2 ]] ; then
    error "ERROR: submit requires at least a WDL and JSON file."
    error ""
    simpleUsage submit
    exit 21
  fi

  local wdl=${1}
  local json=${2}
  local optionsJson=${3}
  local dependenciesZip=${4}

  assertRequiredFileIsNonEmpty "${wdl}" "WDL"
  assertRequiredFileIsNonEmpty "${json}" "Input JSON"

  # At this point, we should validate our inputs if we can:
  which womtool &> /dev/null
  local r=$?
  if [[ ${r} -eq 0 ]] ; then
    echo -ne "Validating WDL and JSON before submission..."
    local tmpValidationOutput=$( makeTemp )
    womtool validate ${wdl} -i ${json} &> ${tmpValidationOutput}
    if [[ $? -eq 0 ]] ; then
      echo -e '\tWDL and JSON are valid.'
    else
      echo
      echo
      error "ERROR: WDL and JSON files do not validate:"  
      cat ${tmpValidationOutput} 1>&2
      exit 8
    fi
  fi

  assertOptionalFileIsNonEmpty "${optionsJson}" "Options JSON"
  assertOptionalFileIsNonEmpty "${dependenciesZip}" "Dependencies Zip"

  assertCanCommunicateWithServer ${CROMWELL_URL}

  echo "Submitting job to server: ${CROMWELL_URL}"

  local response=$(curl -s -F workflowSource=@${wdl}  ${2:+ -F workflowInputs=@${json}} ${3:+ -F workflowOptions=@${optionsJson}} ${4:+ -F workflowDependencies=@${dependenciesZip}} ${CROMWELL_URL}/api/workflows/v1)
  r=$?

  # Check to make sure that we actually submitted the job correctly 
  # and the server ate it well:
   
  # Did the Curl call fail?
  [[ ${r} -ne 0 ]] && error "FAILED TO SUBMIT JOB" && return ${r}

  # Get our status and job ID:
  local st=$( echo "${response}" | jq -r '.status' 2>/dev/null )
  local id=$( echo "${response}" | jq -r '.id' 2>/dev/null )

  # If the status is not `Submitted`, something went wrong:
  if [[ "${st}" != "Submitted" ]] ; then
    turtleDead
    error
    error "Error: Server reports that job was not properly submitted.  Server response:"
    error "${response}"
    exit 9
  fi

  # If the ID is not an ID, something went wrong:
  if [[ $( matchWorkflowId ${id} ) -ne 0 ]] ; then
    turtleDead
    error
    error "Error: Did not get a valid ID back.  Something went wrong.  Server response:"
    error "${response}"
    exit 9
  fi

  # If we get here, we successfully submitted the job and should track it locally:
  turtle
  echo "${response}" 
  
  local runDir=${CROMSHELL_CONFIG_DIR}/${FOLDER_URL}/${id}
  mkdir -p ${runDir}

  cp ${1} ${2} ${3} ${4} ${runDir}/

  echo -e "$(date +%Y%m%d_%H%M%S)\t${CROMWELL_URL}\t${id}\t$(basename ${1})\tSubmitted" >> ${CROMWELL_SUBMISSIONS_FILE}

  # Now that we've submitted our task, we should see if we have to wait:
  if ${doWait} ; then
    waitOnSubmittedStatus ${id} ${CROMWELL_URL}
  fi

  return 0
}

# Check the status of a Cromwell job UUID
function status()
{
  local retVal=0

  assertCanCommunicateWithServer ${2}
  local f=$( makeTemp )
  curl -s ${2}/api/workflows/v1/${1}/status > ${f}
  [[ $? -ne 0 ]] && error "Could not connect to Cromwell server." && rm -f ${f} && return 2

  grep -qE '"Failed"|"Aborted"|"fail"' ${f}
  r=$?
  [[ ${r} -eq 0 ]] && retVal=1

  # Hold our status string here:
  local workflowStatus=$( cat ${f} | jq -r .status )

  if [[ ${retVal} -eq 1 ]]; then
    turtleDead
  elif [[ "${workflowStatus}" == "Running" ]] ; then
    # OK, status claims this workflow is running fine, but we need to check to see
    # if there are any failed sub-processes.
    # To do this, we use the `execution-status-count` logic with some filtering:
    local tmpExecutionStatusCount=$( makeTemp )
    local tmpMetadata=$( makeTemp )

    # Get execution status count and filter the metadata down:
    curl --compressed -s "${2}/api/workflows/v1/${1}/metadata?${CROMWELL_SLIM_METADATA_PARAMETERS}" > ${tmpMetadata}

    jq '.. | .calls? | values | map_values(group_by(.executionStatus) | map({(.[0].executionStatus): . | length}) | add)' ${tmpMetadata} > ${tmpExecutionStatusCount} 

    # Check for failure states:
    cat ${tmpExecutionStatusCount} | grep -q 'Failed'
    r=$?

    # Check for failures:
    if [[ ${r} -ne 0 ]] ; then
      # We could not find 'Fail' in our metadata, so our original status is correct. 
      turtle
    else
      doomedLogo
      workflowStatus="DOOMED"
      local newTempFile=$(makeTemp)
      jq ".status=\"${workflowStatus}\" | .ID=\"${1}\"" ${tmpExecutionStatusCount} > ${newTempFile}
      cp ${newTempFile} ${tmpExecutionStatusCount}
      f=${tmpExecutionStatusCount}
    fi
  else
    turtle
  fi

  # Display status to user:
  cat ${f} | jq .
  checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."

  # Update ${CROMWELL_SUBMISSIONS_FILE}:
  cp ${CROMWELL_SUBMISSIONS_FILE} ${CROMWELL_SUBMISSIONS_FILE}.bak
  awk "BEGIN { FS=OFS=\"\t\" } { if ((\$3 == \"${1}\") && (\$2 == \"${2}\")) { \$5=\"${workflowStatus}\"; }; print }" ${CROMWELL_SUBMISSIONS_FILE}.bak > ${CROMWELL_SUBMISSIONS_FILE}
  #sed -i .bak -e "s#\\(.*${1}.*\\.wdl\\)\\t*.*#\\1$(printf '\t')${workflowStatus}#g" ${CROMWELL_SUBMISSIONS_FILE}

  # Do some cleanup here for daemons:
  rm -f ${f} ${tmpExecutionStatusCount} ${tmpMetadata}

  return ${retVal}
}

# Get the logs of a Cromwell job UUID
function logs() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  curl -s ${2}/api/workflows/v1/${1}/logs | jq .
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the metadata for a Cromwell job UUID
function metadata() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  curl --compressed -s ${2}/api/workflows/v1/${1}/metadata?${CROMWELL_METADATA_PARAMETERS} | jq .
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the metadata in condensed form for a Cromwell job UUID
function slim-metadata() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  curl --compressed -s "${2}/api/workflows/v1/${1}/metadata?${CROMWELL_SLIM_METADATA_PARAMETERS}" | jq .
  checkPipeStatus "Could not connect to Cromwell server." "Could not parse JSON output from cromwell server."
  return $?
}

# Get the status of the given job and how many times it was run
function execution-status-count() 
{
  # Handle Arguments:
  local doPretty=false
  local doExpandSubWorkflows=false
   
  local workflowIDs=""

  # Handling args this way to properly be able to detect negative workflow IDs and
  # workflow IDs themselves.
  # (getopt gets confused when you mix positional and flag args)
  for arg in ${@} ; do
    case ${arg} in
      -p)
        doPretty=true
        ;;
      -x)
        doExpandSubWorkflows=true
        ;;
      -[0-9]*)
          # This is a workflow ID!  
          # Add it to the list:
          workflowIDs="${workflowIDs} ${arg}"
          ;;
      *)
        if [[ $(matchWorkflowId ${arg}) -eq 0 ]] ; then
          # This is a workflow ID!  
          # Add it to the list:
          workflowIDs="${workflowIDs} ${arg}"
        elif aliasExists ${arg} ; then
          #This is an alias, add it to the list
          workflowIDs="${workflowIDs} ${arg}"
        else
          # This is a flag missing an argument!
          invalidSubCommand execution-status-count "missing flag for argument" ${arg}
        fi
        ;;
    esac
  done
  shift $((OPTIND-1))


  # Get our workflow IDs in shape:
  extract_workflow_ids_from_args ${workflowIDs}

  # Go through each workflow ID and get the info we want:
  for wfid in ${WORKFLOW_ID_LIST} ; do

    populateWorkflowIdAndServerUrl ${wfid}
    error "Using workflow-id == ${WORKFLOW_ID}"
    error "Using workflow server URL == ${WORKFLOW_SERVER_URL}"

    assertCanCommunicateWithServer "${WORKFLOW_SERVER_URL}"
    local tempFile=$( makeTemp )
    curl --compressed -s "${WORKFLOW_SERVER_URL}/api/workflows/v1/${WORKFLOW_ID}/metadata?${CROMWELL_SLIM_METADATA_PARAMETERS}" > "${tempFile}"
    local r=$?
    if [[ ${r} -ne 0 ]]  ; then
      error "Error: Could not connect to Cromwell server." 
    fi

    # Make sure the query succeeded:
    if [[ "$( < "${tempFile}" jq '.status' | sed -e 's#^"##g' -e 's#"$##g' )" == 'fail' ]] ; then
      reason=$( < "${tempFile}" jq '.message' | sed -e 's#^"##g' -e 's#"$##g' )
      error "Error: Query to cromwell server failed: ${reason}"
    fi

    if ${doPretty}; then
      # Make it pretty for the user:
      pretty-execution-status ${WORKFLOW_ID} ${tempFile} ${doExpandSubWorkflows}
    else
      # Make it json for a computer:
      # {tasks:{status: count}}
      jq '.. | .calls? | values | map_values(group_by(.executionStatus) | map({(.[0].executionStatus): . | length}) | add)' "${tempFile}"
      checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."
    fi

    # Do some cleanup here for daemon processes.
    rm -f  ${tempFile}
  done
}

#a shorter alias of execution-status-count
function counts()
{
  execution-status-count ${@}
}

# Almost the same as execution-status-count, but prettier!
# Can optionally expand sub-workflows
function pretty-execution-status()
{
  local -r workflowId=${1} metadataFile=${2} expandSubWorkflows=${3:-false}
  local -r workflowStatus=$(jq -r .status ${metadataFile})
  echo -e "${COLOR_UNDERLINED}${workflowId}\t${workflowStatus}${COLOR_NORM}"
  printWorkflowStatus ${metadataFile} "" ${expandSubWorkflows}
}

# Print a workflow (or sub-workflow) pretty-execution-status summary
function printWorkflowStatus()
{
  local -r metadataFile=${1} indent=${2:-""} expandSubWorkflows=${3}
  local -r -a tasks=($(jq -r '.calls | keys | .[]' ${metadataFile}))

  for task in ${tasks[@]}; do
    if $(jq '.calls["'${task}'"][0] | has("subWorkflowMetadata")' ${metadataFile}) && ${expandSubWorkflows}; then
      local subWorkflowName=${task}
      echo -e "\tSubWorkflow ${subWorkflowName}"

      for i in $(seq 0 $(($(jq -r '.calls["'${subWorkflowName}'"] | length ' ${metadataFile}) - 1))); do
        tmpSubWorkflowMetadataFile=$(makeTemp)
        jq '.calls["'${subWorkflowName}'"]['${i}'].subWorkflowMetadata' ${metadataFile} > ${tmpSubWorkflowMetadataFile}
        checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."

        printWorkflowStatus ${tmpSubWorkflowMetadataFile} "${indent}\t" ${expandSubWorkflows}
      done
    else
      printTaskStatus ${task} ${metadataFile} ${indent}
    fi
  done
}

# Print a tasks status and summarize the statuses of shards
function printTaskStatus()
{
  local -r task=${1} metadataFile=${2} indent=${3}
  tmpStatusesFile=$(makeTemp)

  jq -r '.calls["'${task}'"] | group_by(.executionStatus) | map({status: .[0].executionStatus, count: length})[]' ${metadataFile} > ${tmpStatusesFile}
  checkPipeStatus "Could not read tmp file JSON data." "Could not parse JSON output from cromwell server."


  shardsDone=$(jq -r 'select(.status=="Done") | .count' ${tmpStatusesFile})
  shardsRunning=$(jq -r 'select(.status=="Running") | .count' ${tmpStatusesFile})
  shardsFailed=$(jq -r 'select(.status=="Failed") | .count' ${tmpStatusesFile})
  shardsRetried=$(jq -r 'select(.status=="RetryableFailure") | .count' ${tmpStatusesFile})

  taskStatus=''
  if [[ ${shardsFailed} -eq 0 ]] && [[ ${shardsRunning} -eq 0 ]]; then
    taskStatus=${TASK_COLOR_SUCCEEDED}
  elif [[ ${shardsRunning} -ne 0 ]] && [[ ${shardsFailed} -ne 0 ]]; then
    taskStatus=${TASK_COLOR_FAILING} # Running but will fail
  elif [[ ${shardsRunning} -ne 0 ]]; then
    taskStatus=${TASK_COLOR_RUNNING}
  else
    taskStatus=${TASK_COLOR_FAILED}
  fi
  echo -e "${taskStatus}${indent}\t${task}\t${shardsRunning:-0} Running, ${shardsDone:-0} Done, ${shardsRetried:-0} Preempted, ${shardsFailed:-0} Failed${COLOR_NORM}"

  tmpFailedShardsFile=$(makeTemp)
  if [[ 0 -ne shardsFailed ]]; then
    jq -r '.calls["'${task}'"] | group_by(.executionStatus) | map({status: .[0].executionStatus, idx: .[].shardIndex}) | map(select(.status=="Failed")) | map(.idx)' ${metadataFile} > ${tmpFailedShardsFile}
    failedShards=$(tr '\n' ' ' < ${tmpFailedShardsFile} | sed -E 's/\[( )+//' | sed -E 's/( )+\]//')
    echo -e "${taskStatus}${indent}\tFailed shards: ${failedShards}${COLOR_NORM}"
  fi

  rm -f ${tmpFailedShardsFile} ${tmpStatusesFile}
}

# Bring up a browser window to view timing information on the job.
function timing() 
{
  local id=${1}
  local server_url_for_browser=${2}
  turtle
  echo "Opening timing information in your default web browser for job ID: ${id}"
  echo "${server_url_for_browser}" | grep -q "^http"
  r=$?
  if [ $r -ne 0 ]; then
    server_url_for_browser="http://${server_url_for_browser}"
  fi
  server_url_for_browser=${server_url_for_browser}/api/workflows/v1/${id}/timing
  open ${server_url_for_browser}
  echo "URL is: ${server_url_for_browser}"
  return $?
}

# Cancel a running job.
function abort() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  response=$(curl -X POST --header "Content-Type: application/json" --header "Accept: application/json" "${2}/api/workflows/v1/${1}/abort")
  local r=$?
  echo ${response}
  return ${r}
}

# List all jobs submitted in ${CROMWELL_SUBMISSIONS_FILE}
function list()
{
  local doColor=false
  local doUpdate=false

  # Handle Arguments:
  local OPTIND
  while getopts "cu" opt ; do
    case ${opt} in 
      c)
        doColor=true
        ;;
      u)
        doUpdate=true
        ;;
      *)
        invalidSubCommand list flag ${OPTARG}
        ;; 
    esac 
  done
  shift $((OPTIND-1)) 

  # Display the logo:
  turtle

  # If we need to update the data, do so here:
  if ${doUpdate} ; then
    error "Updating cached status list..."
    local tmpFile srv id runSt 

    # Use tput to save the cursor position:
    tput sc

    # The turtle starts 7 rows above where the cursor is at this point,
    # so if we need to move it, we have to move the cursor there before
    # we output anything:
    tput cuu 7

    # Reserve the name for a file whose non-existence will cause 
    # the following loop to exit.
    # This is good because all temp files made with `makeTemp` 
    # are automatically removed at exit, so this sub-process
    # will always die gracefully.
    local flagFile=$(makeTemp)
    echo 'TEST' > ${flagFile}

    # Kick off a turtle spinner...
    _turtleSpinner ${flagFile}

    # Make a copy of our file because we'll be modifying it:
    tmpFile=$( makeTemp )
    cp ${CROMWELL_SUBMISSIONS_FILE} ${tmpFile}

    local unreachable_servers=""
    local reachable_servers=""
    while read line ; do
      id=$( echo "$line" | awk '{print $3}' )
      # Only update if the ID field is, in fact, a valid ID:
      if [[ $(matchWorkflowId ${id}) -eq 0 ]] ; then
        srv=$( echo "$line" | awk '{print $2}' )
        if echo ${unreachable_servers} | grep -q ${srv}; then
          continue # we already know that server is unreachable
        elif echo ${reachable_servers} | grep -q ${srv}; then
          # we know that server should be reachable, practically speaking during this update operation
          runSt=$( echo "$line" | awk '{print $5}' )

          # get the status of the run if it has not completed:
          if [[ "${runSt}" != "Failed" ]] && [[ "${runSt}" != "Aborted" ]] && [[ "${runSt}" != "Succeeded" ]] ; then
            status ${id} ${srv} &> /dev/null
          fi
        elif [[ $(curl -m 1 -s ${srv}) ]]; then
          reachable_servers+=" ${srv}"
          
          runSt=$( echo "$line" | awk '{print $5}' )

          # get the status of the run if it has not completed:
          if [[ "${runSt}" != "Failed" ]] && [[ "${runSt}" != "Aborted" ]] && [[ "${runSt}" != "Succeeded" ]] ; then
            status ${id} ${srv} &> /dev/null
          fi
        else
          unreachable_servers+=" ${srv}"
        fi
      fi
    done < ${tmpFile}

    # Remove the flag file to kill the spinner and wait for it to finish:
    rm ${flagFile}
    wait

    # Restore cursor position:
    tput rc
  fi
  if [[ ! -z ${UNREACHABLE_SERVER} ]]; then
    local pretty_ugly=$(echo ${UNREACHABLE_SERVER} | sed 's/ /\n/g')
    error "The following cromwell servers cannot be reached and were skipped\n${pretty_ugly}\n"
  fi

  # If we have to colorize the output, we do so:
  if ${doColor} ; then

    local tmpFile=$( makeTemp )  
    cat ${CROMWELL_SUBMISSIONS_FILE} | column -t > ${tmpFile}

    while read line ; do 

      # Check for header line:
      echo "${line}" | grep -q '^DATE' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_UNDERLINED}${line}${COLOR_NORM}" && continue

      # Check for jobs that WILL FAIL and color those lines:
      echo "${line}" | grep -q 'DOOMED' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_DOOMED}${line}${COLOR_NORM}" && continue
      
      # Check for failed jobs and color those lines:
      echo "${line}" | grep -q 'Failed' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_FAILED}${line}${COLOR_NORM}" && continue

      # Check for Aborted jobs and color those lines:
      echo "${line}" | grep -q 'Aborted' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_ABORTED}${line}${COLOR_NORM}" && continue

      # Check for successful jobs and color those lines:
      echo "${line}" | grep -q 'Succeeded' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_SUCCEEDED}${line}${COLOR_NORM}" && continue

      # Check for running jobs and color those lines:
      echo "${line}" | grep -q 'Running' 
      r=$?
      [[ ${r} -eq 0 ]] && echo -e "${COLOR_RUNNING}${line}${COLOR_NORM}" && continue

      echo "${line}"  
    done < ${tmpFile} 
  else  
    cat ${CROMWELL_SUBMISSIONS_FILE} | column -t
  fi
  return $?
}

function cleanup() 
{
  local st="" 

  # Handle Arguments:
  local OPTIND
  while getopts "s:" opt ; do
    case ${opt} in 
      s)
        local isGood=false
        for okVal in ${TERMINAL_STATES} ; do 
          if [[ "${OPTARG}" == "${okVal}" ]] ; then 
            isGood=true
          fi
        done 

        if ! ${isGood} ; then
          invalidSubCommand cleanup STATUS ${OPTARG}
        fi

        st="${st} ${OPTARG}"
        ;;
      *)
        invalidSubCommand cleanup flag ${OPTARG}
        ;; 
    esac 
  done
  shift $((OPTIND-1)) 

  # Make sure we don't have any extra arguments here:
  if [[ $# -ne 0 ]] ; then
    invalidSubCommand cleanup flag "${@}"
  fi  

  # Get all states if we don't specify one:  
  if [[ ${#st} -eq 0 ]] ; then
    st=${TERMINAL_STATES}
  fi

  # Display the logo:
  turtle
  echo

  # Remove the lines:
  local tmpFile=$( makeTemp )
  local tmpFile_remove=$( makeTemp )

  echo "I'm looking for records with the following states: ${st}"
  echo
  while read line ; do
    for s in ${st} ; do
      # Go through each line and filter by status, which is the 5th column:
        lineStatus=$( echo ${line} | awk '{print $5}' )
        if [[ "${lineStatus}" == "${s}" ]] ; then
          echo ${line} >> ${tmpFile_remove}
          continue 2
        fi
    done
    echo ${line} >> ${tmpFile}
  done < ${CROMWELL_SUBMISSIONS_FILE}

  echo "The following records are about to be removed:"
  echo

    cat ${tmpFile_remove}| column -t

  echo
  getAnswerFromUser "Are you sure you want to CLEAR the listed records? " 'Yes No' answer

  if [[ $( echo "${answer}" | tr A-Z a-z ) == "yes" ]] ; then
    echo "User answered 'Yes'."
    echo

    #Backup the file:
    echo "Creating backup of records file:"
    cp -v ${CROMWELL_SUBMISSIONS_FILE} ${CROMWELL_SUBMISSIONS_FILE}.$(date +%Y%m%dT%H%M%S ).bak
  echo

     # Copy the temp file to the final file location for the next
     # iteration or for when we're done
     cp ${tmpFile} ${CROMWELL_SUBMISSIONS_FILE}

    echo 'Your cromshell logs are now clean.'
    return 0
  else
    echo "Not clearing logs.  User aborted..."
    return 1
  fi
}


function assertDialogExists()
{
  which dialog &>/dev/null   
  r=$?
  [[ ${r} -ne 0 ]] && error "dialog does not exist.  Must install \`dialog\`: (yum install dialog / brew install dialog / apt-get dialog)." && exit 8
}

function assertGsUtilExists()
{
  which gsutil &>/dev/null   
  r=$?
  [[ ${r} -ne 0 ]] && error "gsutil does not exist.  Must install google cloud utilities." && exit 8
}

# List the output files for a given run.
# Will list all output files that are not:
#     *.log
#     rc
#     stdout
#     stderr
#     script
#     output
function list-outputs() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  local id=${1}
  local cromwellServer=${2}

  local remoteFolder=$( metadata ${id} ${cromwellServer} 2>/dev/null | grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  assertGsUtilExists

  error "Output files from job ${cromwellServer}:${id} : "

  tmpFolder=$(mktemp -d)

  # The -n flag just lists what would have happened if the copy occurred
  # we use this to our advantage to list the files we want:
  gsutil rsync -rP -n -x '.*\.[Ll][oO][Gg]$|.*rc|.*stdout|.*stderr|.*script|.*output|.*gcs_delocalization\.sh|.*gcs_localization\.sh|.*gcs_transfer\.sh|.*cromwell_glob_control_file|.*glob-[a-fA-F0-9]*\.list' ${remoteFolder}/ ${tmpFolder}/. 2>&1 | \
    grep 'Would copy' | \
    sed 's#Would copy \(.*\) to .*#\1#g'

  # Clean up our mess
  rmdir ${tmpFolder}

  return 0
}


# Get the root log folder from the cloud and put it in the metadata folder for this run
function fetch-logs() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  local id=${1}
  local cromwellServer=${2}

  local remoteFolder=$( metadata ${id} ${cromwellServer} 2>/dev/null| grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  assertGsUtilExists

  mkdir -p ${localServerFolder}

  error "Retrieving logs from ${remoteFolder}"
  error "Copying into ${localServerFolder}"

  # Do the copy, filtering for log files only:
  # Specifically, it will copy all files:
  #     - ending in .log (case insensitive)
  #     - Named rc
  #     - Named stdout
  #     - Named stderr
  #     - Named script
  gsutil rsync -rP -x '^(?!.*\.[Ll][oO][Gg]$|.*rc|.*stdout|.*stderr|.*script).*' ${remoteFolder}/ ${localServerFolder}/.

  error "Files copied to local folder: ${localServerFolder}"

  return 0
}

# Get the root log folder from the cloud and put it in the metadata folder for this run
# Includes all logs and output files
function fetch-all() 
{
  assertCanCommunicateWithServer ${2}
  turtle
  local id=${1}
  local cromwellServer=${2}

  local remoteFolder=$( metadata ${id} ${cromwellServer} 2>/dev/null | grep "\"callRoot\":" | head -n1 | awk '{print $2}' | sed "s#\"\\(.*${id}\\).*#\\1#g" )

  local localServerFolder="${CROMSHELL_CONFIG_DIR}/$( echo "${cromwellServer}" | sed -e 's#ht.*://##g' )/${id}"

  assertGsUtilExists

  mkdir -p ${localServerFolder}

  error "Retrieving logs from ${remoteFolder}"
  error "Copying into ${localServerFolder}"
  gsutil rsync -rP ${remoteFolder}/ ${localServerFolder}/.

  error "Files copied to local folder: ${localServerFolder}"

  return 0
}

function _cost_helper() 
{
  local id=$1
  local svr=$2

  turtle
  which bq &>/dev/null   
  local r=$?
  [[ ${r} -ne 0 ]] && error "bq does not exist.  Must install the big query command-line client." && exit 8

  # Check for gdate:
  if [[ "$(uname)" == "Darwin" ]] ; then
    which gdate &> /dev/null
    r=$?
    [ $r -ne 0 ] && error "Must have coreutils installed for 'gdate'" && exit 13
  fi

  [ ! -e ${BQ_COST_TABLE_FILE} ] && error "Big Query cost table file does not exist.  Must populate ${BQ_COST_TABLE_FILE} with big query cost table information." && exit 9

  # Make sure the given ID is actually in our file:
  grep -q "${id}" ${CROMWELL_SUBMISSIONS_FILE} 
  r=$?
  [ $r -ne 0 ] && error "Given ID is not in your cromwell submissions file (${CROMWELL_SUBMISSIONS_FILE}): ${id}" && exit 10

  COST_TABLE=$(head -n1 ${BQ_COST_TABLE_FILE})
  
  # Get the time that the workflow finished:
  error "Fetching workflow finish time..."
  tmpMetadata=$( makeTemp )
  curl --compressed -s "${svr}/api/workflows/v1/${id}/metadata?includeKey=workflowProcessingEvents" > ${tmpMetadata}

  [ ! -s ${tmpMetadata} ] && error "Could not communicate with server.  Perhaps try a longer timeout." && exit 15

  grep -q '"description":"Finished",' ${tmpMetadata}
  r=$?
  [ $r -ne 0 ] && error "Workflow ${id} is not finished yet." && exit 11

  STARTED_TIME=$( jq '.workflowProcessingEvents | map(select(.description == "PickedUp")) | .[].timestamp' ${tmpMetadata} | tr -d '"')
  FINISHED_TIME=$( jq '.workflowProcessingEvents | map(select(.description == "Finished")) | .[].timestamp' ${tmpMetadata} | tr -d '"')

  # Make sure that at least 8h have passed since the workflow finished:
  if [[ "$(uname)" == "Darwin" ]] ; then
    local DATE_CMD=gdate
  else
    local DATE_CMD=date
  fi  

	local WAITING_PERIOD_s=$(echo "3600 * 24" | bc)

  local ts1=$( $DATE_CMD +%s -d "${FINISHED_TIME}" )
  local ts2=$( date +%s )
  local time_diff=$(echo "${ts2} - ${ts1}" | bc)
  local can_check_cost=$( echo "${time_diff} >= ${WAITING_PERIOD_s}" | bc )

  if [ $can_check_cost -ne 1 ] ; then

		local total_wait_time_s=$(echo "${WAITING_PERIOD_s} - ${time_diff}" | bc)
    local wait_time_h=$(echo "scale=0;${total_wait_time_s} / 3600" | bc)
    local wait_time_m=$(echo "scale=0;(${total_wait_time_s} % 3600) / 60" | bc)
    local wait_time_s=$(echo "scale=0;(${total_wait_time_s} % 3600) % 60" | bc)

    # Format the time:
    [[ ${#wait_time_h} -lt 2 ]] && wait_time_h="0${wait_time_h}"
    [[ ${#wait_time_m} -lt 2 ]] && wait_time_m="0${wait_time_m}"
    [[ ${#wait_time_s} -lt 2 ]] && wait_time_s="0${wait_time_s}"

    error "Workflow finished less than 24 hours ago.  Cannot check cost.  Please wait ${wait_time_h}h:${wait_time_m}m:${wait_time_s}s and try again." 
    exit 12
  fi

  # Generate the start and end dates for our query:
  START_DATE=$($DATE_CMD +%Y-%m-%d -d "${STARTED_TIME} -1 day")
  END_DATE=$($DATE_CMD +%Y-%m-%d -d "${FINISHED_TIME} +1 day")

  error "Using cost table: ${COST_TABLE}"
  error ""
}

# Get the cost for a workflow ID:
function cost()
{
  local id=$1
  local svr=$2
  _cost_helper $id $svr

  local tmp_cost_file=$( makeTemp )

  # Get the cost from Big Query:
  bq query --use_legacy_sql=false "SELECT sum(cost) FROM \`${COST_TABLE}\`, UNNEST(labels) WHERE value = \"cromwell-${id}\" AND _PARTITIONDATE BETWEEN \"${START_DATE}\" AND \"${END_DATE}\";" > ${tmp_cost_file}
  r=$?

  # Display the cost:
  total_cost=$( head -n4 ${tmp_cost_file} | tail -n1 | tr -d '| \t')
  [[ "${total_cost}" == NULL ]] && error "Could not retrieve cost - no cost entries found." && exit 14
  echo -n '$'
  echo "scale=2;${total_cost}/1" | bc

  error ""
  error "Costs rounded to nearest cent (approximately)."
  error ""
  error "WARNING: Costs here DO NOT include any call cached tasks."

  return $r
}

# Get the cost for a workflow ID:
function cost-detailed()
{
  local id=$1
  local svr=$2
  _cost_helper $id $svr

  local tmp_cost_file=$( makeTemp )

  # Get the cost from Big Query:
  bq query \
    --use_legacy_sql=false \
    "SELECT
    wfid.value, service.description, task.value as task_name, sum(cost) as cost
    FROM
    \`${COST_TABLE}\` as billing, UNNEST(labels) as wfid, UNNEST(labels) as task
    WHERE
    cost > 0
    AND task.key LIKE \"wdl-task-name\"
    AND wfid.key LIKE \"cromwell-workflow-id\"
    AND wfid.value like \"%${id}\"
    AND _PARTITIONDATE BETWEEN \"${START_DATE}\" AND \"${END_DATE}\"
    GROUP BY 1,2,3
    ORDER BY 4 DESC
    ;" | tail -n+4 | grep -v '^+' | tr -d '|' | awk 'BEGIN{OFS="\t"}{print $(NF-1), $NF}' | sort > ${tmp_cost_file}

  r=$?

  local total_cost=$(awk '{print $2}' ${tmp_cost_file} | tr '\n' '+' | sed 's#$#0#' | bc)
  local total_cost=$(echo "scale=2;${total_cost}/1" | bc)

  local tmpf2=$(makeTemp)
  echo -e "TASK\tCOST" > ${tmpf2}
  while read line ; do
    local task=$(echo $line | awk '{print $1}')
    local task_cost=$(echo $line | awk '{print $2}')
    task_cost=$(echo "scale=2;if ( ${task_cost} >= 0.01 ) { ${task_cost}/1; } else { 0.01 }" | bc)
    printf "${task}\t$%02.2f\n" ${task_cost}
  done < ${tmp_cost_file} >> ${tmpf2}

  column -t ${tmpf2} | head -n1
  local bar_width=$( column -t ${tmpf2} | head -n1 | wc -c )  
  python -c "print('=' * ${bar_width})"
  column -t ${tmpf2} | tail -n+2
  python -c "print('=' * ${bar_width})"
  echo "Total Cost: \$${total_cost}"

  error ""
  error "Costs rounded to nearest cent (approximately)."
  error ""
  error "WARNING: Costs here DO NOT include any call cached tasks."

  return $r
}

function assertValidEmail() 
{
  # Make sure the user gave us a good email address:
  echo "${1}" | grep -q  '@'
  r=$?
  if [[ ${r} -ne 0 ]] ; then
    error "Error: invalid email address: ${1}"
    error ""
    simpleUsage notify
    echo "Try \`${SCRIPTNAME} -h' for more information."
    exit 5
  fi
}

# Spin off a task in the background that will check periodically if the workflow ID is 
# complete.
# When it is, send an email to the email address specified.
function notify()
{
  if [[ $# -lt 1 ]] ; then
    error "Error: You must specify an email address to notify."
    error ""
    simpleUsage notify
    echo "Try \`${SCRIPTNAME} -h' for more information."
    exit 5
  fi

  # Is the next argument our workflow ID?
  # Workflow IDs are standard UUIDs or negative numbers:
  if [[ $(matchWorkflowId ${1}) -eq 0 ]] || [[ $( matchRelativeWorkflowId ${1} ) -eq 0 ]] || aliasExists ${1} ; then
    # Get the workflow ID:
    populateWorkflowIdAndServerUrl ${1}
    shift
  fi

  # Get the host on which this will be run:
  hostServer="${HOSTNAME}"

  if [[ ! "${1}" =~ ^.*@.*  ]] ; then
    hostServer=${1}
    shift
  fi

  # Make sure the user gave us a good email address:
  assertValidEmail ${1}
  email=${1}
  shift

  # Make sure our workflow ID is populated:
  populateWorkflowIdAndServerUrl ${WORKFLOW_ID}

  # Make sure we have a workflow server defined.
  # This is important if we're on a remote server for the notification
  # daemon.
  if [[ ${#WORKFLOW_SERVER_URL} -eq 0 ]] ; then
    if [[ ${#1} -ne 0 ]] ; then
      WORKFLOW_SERVER_URL="${1}"
      shift
    else
      error 'Error: Could not determine the cromwell server url!'
      exit 2
    fi
  fi

  # Do some wizardry here to spin off the notification daemon on a remote server:
  if [[ "${hostServer}" != "${HOSTNAME}" ]] ; then
    turtle
    error "Creating notification daemon on host ${hostServer} ..."

    # Send the script to the server:
    local tmpOut=$( makeTemp )
    scp ${SCRIPTDIR}/${SCRIPTNAME} ${hostServer}:~/. &> ${tmpOut}
    [[ $? -ne 0 ]] && error "ERROR: Could not copy cromshell to server ${hostServer}" && error "$(cat ${tmpOut})" && rm -f ${tmpOut} && exit 7
    rm -f ${tmpOut}

    # Spin off notification process on the server:
    results=$( ssh ${hostServer} "~/${SCRIPTNAME} _rawNotify ${WORKFLOW_ID} ${email} ${WORKFLOW_SERVER_URL}" )
    [[ $? -ne 0 ]] && error "ERROR: Could not start notification daemon on ${hostServer}" && exit 8

    # Let the user know we've done our job:
    echo "Spun off thread on ${hostServer} - PID = $( echo "${results}" | grep "Spun off thread on PID" | sed 's#Spun off thread on PID ##g' )"
  else
    _rawNotify ${WORKFLOW_ID} ${email} ${WORKFLOW_SERVER_URL}
  fi
}

# Perform a raw notification without validating any input arguments.
function _rawNotify() 
{
  local WORKFLOW_ID=$1
  local email=$2
  local WORKFLOW_SERVER_URL=$3

  error "Spinning off notification thread to ${email} for"
  error "    workflow:             ${WORKFLOW_ID}" 
  error "    from Cromwell server: ${WORKFLOW_SERVER_URL}"
  error "..."
  nohup bash -c "source ${SCRIPTDIR}/${SCRIPTNAME}; _notifyHelper ${WORKFLOW_ID} ${email} ${WORKFLOW_SERVER_URL}" &>/dev/null &
  echo "Spun off thread on PID $!"
}

# Helper function for the notify command that actually notifies the user:
function _notifyHelper()
{
  local id=${1}
  local email=${2}
  local cromwellServer=${3}

  assertCanCommunicateWithServer ${cromwellServer}
  local separator="=================================================="
  local statusFile=$( makeTemp )

  while true ; do 
   
    status ${id} ${cromwellServer} 2>/dev/null > ${statusFile}
    completionStatus=$( jq -r '.status' ${statusFile} )

    if [[ "${completionStatus}" == "Succeeded" ]] || \
       [[ "${completionStatus}" == "Failed" ]] || \
       [[ "${completionStatus}" == "Aborted" ]] || \
       [[ "${completionStatus}" == "DOOMED" ]] ; then
      workflowFile=$( grep '$id' ${CROMWELL_SUBMISSIONS_FILE} | head -n1 | awk '{print $4}' ) 
      metaData=$( metadata ${id} ${cromwellServer} )
      echo -e "CROMWELL Task ${completionStatus}:\n\n${id}\n\non\n\n${cromwellServer}\n\n${separator}\n\nStatus:\n$(cat ${statusFile})\n\n${separator}\nMetadata:\n${metaData}\n\n${separator}\nSent by $( whoami )@$( hostname ) on $( date ) \n\n\n" | mail -n -s "Cromwell Task ${completionStatus} [${cromwellServer}] ${workflowFile}" ${email}
      rm -f ${statusFile}
      break
    fi
    # Clean the temporary file just in case.  
    # This might need to happen because of how this helper gets called.
    # Not sure the trap is working properly (i.e. it doesn't seem to be calling at_exit).
    rm -f ${statusFile}

    # wait for 10 seconds:
    sleep 10
  done 
}

function runSubCommandOnWorkflowId()
{
  # Get the workflow ID:
  populateWorkflowIdAndServerUrl ${1}
  shift
  error "Using workflow-id == ${WORKFLOW_ID}"
  error "Using workflow server URL == ${WORKFLOW_SERVER_URL}"
  ${SUB_COMMAND} ${WORKFLOW_ID} ${WORKFLOW_SERVER_URL}
  r=$?
  echo
  return ${r}
}

function dialogAskUserIfUrlIsOK()
{
  local BACKTITLE=${1}
  local url=${2}
  local menuFile=${3}

  # Dialog to validate that the user has entered the correct thing:
  dialog --clear --backtitle "${BACKTITLE}" --title "Cromwell URL Verification" \
    --yesno "Oh my!  It looks like your server is: \n\
\n\
${url}\n\
\n\
Is this correct?" 10 75 2>${menuFile}
  local r=$?

  return ${r}
}

function checkForUserQuitDialogEarly()
{
  # If the user gets cold feet, let them go softly into the night.
  if [[ ${1} -ne 0 ]] ; then
    clear 
    error "   User aborted setup."
    error ""
    turtle
    error ""
    error "  Please come back soon!"
    exit 6
  fi
}

function setupCromshellDialog()
{
  assertDialogExists

  local menuFile=$( makeTemp )
  local splashTextFile=$( makeTemp )

  # Menu variables:
  local TITLE="Welcome to Cromshell!"
  local BACKTITLE="Cromshell First Time Setup"
  local URL_QUESTION_TEXT="What is the URL of the Cromwell server you use to execute your jobs?"
  local r

  # Set up our logo:
  turtle &> ${menuFile} 
  sed 's#^#     #g' ${menuFile} > ${splashTextFile}
  
  # Splash screen:
  dialog --beep --exit-label "Continue" --backtitle "${BACKTITLE}" --title "${TITLE}" --textbox ${splashTextFile} 12 43
  r=$?

  # URL input dialog:
  dialog --clear --backtitle "${BACKTITLE}" --title "${TITLE}" \
    --inputbox "This seems to be your first time running me, Cromshell! \n\
(Please excuse me if it isn't!  I seem to have forgotten some of your information!)\n\
\n\
I am your personal, personable, and wonderful extension of the Cromwell API right here on the command-line.\n\
\n\
There are a few small questions I need you to answer before I can make your cromwell dreams come true.\n\
\n\
${URL_QUESTION_TEXT}" 20 75 2> ${menuFile} 
  r=$?

  checkForUserQuitDialogEarly ${r}

  local hasGoodUrl=false

  # Get the URL from the menu file:
  url=$( cat ${menuFile} | sed -e 's#^[ \t]*##g' -e 's#[ \t]*$##g' )

  # Dialog to validate that the user has entered the correct thing:
  dialogAskUserIfUrlIsOK "${BACKTITLE}" "${url}" "${menuFile}"
  r=$?

  # See if the user is OK with their URL:
  if [[ ${r} -eq 0 ]] ; then
    hasGoodUrl=true
  fi

  # Until we have a good URL, we need to keep asking the user.
  while ! ${hasGoodUrl} ; do

    # URL input dialog:
    dialog --clear \
      --backtitle "${BACKTITLE}" \
      --title "Cromwell URL Verification" \
      --inputbox "Oh, I'm terribly sorry for that.  Let's try again! \n\
\n\
${URL_QUESTION_TEXT}" 10 75 2> ${menuFile} 
    r=$?

    checkForUserQuitDialogEarly ${r}

    # Get the URL from the menu file:
    url=$( cat ${menuFile} | sed -e 's#^[ \t]*##g' -e 's#[ \t]*$##g' )

    # Dialog to validate that the user has entered the correct thing:
    dialogAskUserIfUrlIsOK "${BACKTITLE}" "${url}" "${menuFile}"
    r=$?

    # See if the user is OK with their URL:
    if [[ ${r} -eq 0 ]] ; then
      hasGoodUrl=true
    fi
  done
  
  # Put the URL in the file:
  echo "${url}" > ${CROMWELL_SERVER_FILE}

  # Thank the user for their input and let them know 
  # they are ready to run:
  echo -e "" > ${splashTextFile}
  echo -e "OK.  I have set your Cromwell server to be:" >> ${splashTextFile}
  echo -e "" >> ${splashTextFile}
  echo -e "${url}" >> ${splashTextFile}
  echo -e "" >> ${splashTextFile}
  echo -e "You should be ALL SET!" >> ${splashTextFile}
  echo -e "Please run me again to start the executions." >> ${splashTextFile}

  dialog --clear --beep --exit-label "Continue" --backtitle "${BACKTITLE}" --title "${TITLE}" --textbox ${splashTextFile} 13 75
  r=$?

  clear

  return 0
}

function setupCromshell() 
{
  echo "--------------------------------------------------"
  echo -e "   __        __   _                          "
  echo -e "   \\ \\      / /__| | ___ ___  _ __ ___   ___ "
  echo -e "    \\ \\ /\\ / / _ \\ |/ __/ _ \\| '_ \` _ \\ / _ \\"
  echo -e "     \\ V  V /  __/ | (_| (_) | | | | | |  __/"
  echo -e "      \\_/\\_/ \\___|_|\\___\\___/|_| |_| |_|\\___|"
  echo -e "                                             "
  echo -e "                    _        "
  echo -e "                   | |_ ___  "
  echo -e "                   | __/ _ \\ "
  echo -e "                   | || (_) |"
  echo -e "                    \\__\\___/ "
  echo -e "                             "
  echo -e "   ____                         _          _ _ "
  echo -e "  / ___|_ __ ___  _ __ ___  ___| |__   ___| | |"
  echo -e " | |   | '__/ _ \\| '_ \` _ \\/ __| '_ \\ / _ \\ | |"
  echo -e " | |___| | | (_) | | | | | \__ \ | | |  __/ | |"
  echo -e "  \\____|_|  \\___/|_| |_| |_|___/_| |_|\\___|_|_|"
  echo -e "                                               "
  
  echo
  turtle
  echo

  echo "--------------------------------------------------"

  echo
  echo 'This seems to be your first time running me, Cromshell!'
  echo "(Please excuse me if it isn't!  I seem to have forgotten"
  echo 'some of your information!)'
  echo ''
  echo "I am your personal, personable, and wonderful extension of "
  echo "the Cromwell API right here on the command-line."
  echo ""
  echo "There are a few small questions I need you to answer before"
  echo "I can make your cromwell dreams come true."
  echo
  echo "--------------------------------------------------"
  echo

  # Get the server they need to connect to:
  local chooseServer=false
  while ! ${chooseServer} ; do
    echo "What is the URL of the Cromwell server you use to execute"
    echo "your jobs?"

    # Read in the URL:
    read -p "Cromwell URL, please: " url
    echo

    # Force the user to acknowledge their input:
    getAnswerFromUser "Oh my!  It looks like your server is: ${url}$(echo $'\nIs this correct')" 'Yes No' answer

    if [[ $( echo "${answer}" | tr A-Z a-z ) == "yes" ]] ; then
      chooseServer=true
    else
      echo "Oh, I'm terribly sorry for that.  Let's try again!"
      echo
      echo
    fi
  done

  echo
  echo "OK.  I'm now setting your Cromwell server to be: ${url}"
  echo -n "Don't worry - this won't hurt a bit..."
  
  # Put the URL in the file:
  echo "${url}" > ${CROMWELL_SERVER_FILE}
  echo "DONE"

  echo
  echo "OK, you should be ALL SET!"
  echo "Please run me again to start the executions."
}

################################################################################

# Do all the interactive stuff if the script is called by a user.
# The bash equivalent to `if __name__ == '__main__':
if ${ISINTERACTIVESHELL} ; then

  # Check the remaining arguments for help and display it if we have to: 
  checkForComplexHelpArgument $@

  # Get flags:
  while getopts ":t:" opt ; do
    case ${opt} in 
      t)
        # Ensure that the value given to -t is numerical:
        echo ${OPTARG} | grep -q -E '^[0-9]+$' 
        rv=$?
        [[ ${rv} -ne 0 ]] && invalidSubCommand '' "flag value (${OPTARG})" "-${opt} argument must be an integer."

        # Set our timeouts:
        CURL_CONNECT_TIMEOUT=${OPTARG}
        let CURL_MAX_TIMEOUT=2*${CURL_CONNECT_TIMEOUT}
        ;;
      :)
        invalidSubCommand '' 'flag value' "-${opt} requires an argument."
        ;;
      *)
        invalidSubCommand '' flag ${OPTARG}
        ;; 
    esac 
  done
  shift $((OPTIND-1)) 

  # Get our sub-command:
  SUB_COMMAND=${1}
  shift

  # Use the update-server sub-command to modify CROMWELL_NEEDS_SETUP here.
  if [[ "${SUB_COMMAND}" == "update-server" ]] ; then
    CROMWELL_NEEDS_SETUP=true
  fi
  
  # Check if we need to set this up.
  # Note: because of how `notify` works, we can't require the setup for the notify action.
  if ${CROMWELL_NEEDS_SETUP} && [[ "${SUB_COMMAND}" != "notify" ]] ; then
    # We need to setup this install.
    # Now let's set it up:
    which dialog &> /dev/null
    r=$?
     if [[ ${r} -eq 0 ]] ; then
      setupCromshellDialog
    else
      setupCromshell
    fi
    exit 0
  fi

  # Validate our sub-command:
  case ${SUB_COMMAND} in
    cleanup|submit|status|cost|cost-detailed|logs|execution-status-count|counts|metadata|slim-metadata|timing|abort|notify|list|fetch-all|fetch-logs|list-outputs|alias)
      # This is a good sub-command, so we do not need to do anything. 
      ;;
    _rawNotify)
      # This is a valid internal sub-command.  
      # While it should never be called directly by the user, it is possible that this was called by another command in this script.
      ;;
    *)
      if [[ ${#SUB_COMMAND} -eq 0 ]]; then
        simpleUsage 
        exit 0
      else   
        invalidSubCommand '' "sub-command" "${SUB_COMMAND}"
      fi
      ;; 
  esac

  # Now that we have checked for help arguments, we can
  # make sure we have all the required commands:
  checkPrerequisites ${PREREQUISITES}
  r=$?
  [[ ${r} -ne 0 ]] && exit 6

  # Sanitize the displayed sub-command:
  SUB_COMMAND_FOR_DISPLAY=${SUB_COMMAND}
  case ${SUB_COMMAND} in
    _rawNotify)
      SUB_COMMAND_FOR_DISPLAY="notify"
      ;;
    alias)
      SUB_COMMAND="alias_workflow"
      ;;
  esac

  # Don't check JQ version if we're notifying.
  # Why do this, you might ask?
  # Because it's easier to hack our code than to get Broad IT to update software on our servers.
  if [[ "${SUB_COMMAND_FOR_DISPLAY}" != "notify" ]] ; then
    checkJQVersion
    r=$?
    [[ ${r} -ne 0 ]] && exit 6
  fi

  # Handle specific sub-command args and and call our sub-command:
  error "Sub-Command: ${SUB_COMMAND_FOR_DISPLAY}"
  case ${SUB_COMMAND} in 
    # These are the sub-commands that take arguments other than workflow IDs:
    cleanup|submit|list|notify|execution-status-count|counts|alias_workflow)
      ${SUB_COMMAND} $@
      rv=$?
      ;;
    # These are internal sub-commands that take arguments that should not be modified:
    _rawNotify)
      ${SUB_COMMAND} $@
      rv=$?
      ;;
    # Handle sub-commands that only take workflow IDs:  
    *)
      extract_workflow_ids_from_args $@

      for WORKFLOW_ID in ${WORKFLOW_ID_LIST} ; do 
        runSubCommandOnWorkflowId ${WORKFLOW_ID} 
        rv=$?
      done
      ;;
  esac

  exit ${rv}
fi
